{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c04cdb8c-c33f-4b0f-9533-f3d1caec0e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_456912/2633986274.py:64: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.92718868  1.24146073  1.15574473 ...  0.89859675  0.12715279\n",
      " -1.24430312]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train_scaled.iloc[:,0:9] = scaler.fit_transform(X_train_scaled.iloc[:,0:9])\n",
      "/tmp/ipykernel_456912/2633986274.py:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.15858713  0.47001677 -0.12999519  0.72716476 -1.5871671   1.92718868\n",
      " -0.0442792   0.55573277  1.6700407   0.0414368  -0.47285917 -0.12999519\n",
      "  0.38430078 -0.21571118 -0.90143914 -2.95862302  1.24146073 -1.50145111\n",
      "  1.15574473  1.07002874  1.32717672  0.72716476  0.12715279 -0.64429116\n",
      " -1.41573511 -0.55857516  1.24146073 -0.55857516  0.98431274 -0.30142718\n",
      "  0.38430078 -1.5871671   0.38430078 -1.50145111 -2.35861105 -1.50145111\n",
      " -0.90143914 -0.73000715  1.84147269 -2.27289506 -0.21571118  1.49860871\n",
      " -0.73000715  3.04149661  0.12715279  0.81288075  1.41289271 -0.38714317\n",
      "  0.72716476 -1.15858713  0.12715279 -1.41573511  1.07002874 -0.21571118\n",
      "  1.41289271 -0.90143914 -0.30142718  1.5843247   1.15574473 -1.07287113\n",
      " -1.07287113  0.0414368  -0.81572315 -2.01574707  1.32717672  1.07002874\n",
      "  1.32717672  1.32717672 -0.73000715 -0.98715514  0.72716476  1.6700407\n",
      "  1.32717672 -0.98715514  0.55573277  1.6700407  -0.98715514 -0.38714317\n",
      "  0.89859675  0.98431274 -0.0442792   0.21286879 -0.0442792   1.6700407\n",
      "  0.12715279  0.38430078 -0.47285917 -0.55857516  0.89859675 -1.24430312\n",
      "  0.47001677 -0.0442792   0.29858478  1.07002874  1.24146073  0.29858478\n",
      "  0.0414368  -0.64429116 -0.55857516  0.72716476 -0.21571118 -1.75859909\n",
      "  0.64144876 -0.73000715  1.15574473 -0.64429116  0.47001677 -0.55857516\n",
      " -0.47285917 -1.75859909 -0.0442792  -0.81572315 -1.24430312  1.32717672\n",
      "  1.41289271  1.5843247   0.64144876 -1.67288309  1.32717672 -0.55857516\n",
      "  1.75575669  2.09862067  1.41289271 -1.41573511 -1.50145111 -1.41573511\n",
      "  0.29858478 -1.50145111  0.89859675 -0.30142718 -0.0442792   1.84147269\n",
      "  0.38430078  0.12715279  0.0414368   1.24146073  1.41289271  0.47001677\n",
      " -0.0442792  -1.50145111  0.21286879  0.81288075  0.0414368  -1.75859909\n",
      "  0.12715279  0.89859675 -0.98715514  1.75575669 -0.55857516 -0.21571118\n",
      "  0.0414368  -1.67288309  0.47001677  0.55573277  1.49860871  1.41289271\n",
      " -1.5871671  -1.93003108 -0.21571118 -1.5871671   1.75575669 -2.18717906\n",
      "  0.21286879  0.0414368   0.47001677 -0.12999519 -0.0442792   0.38430078\n",
      " -2.27289506  1.24146073 -0.90143914  0.12715279  1.15574473 -1.33001912\n",
      "  1.92718868  1.49860871 -1.67288309 -1.33001912 -0.0442792   0.29858478\n",
      "  1.07002874 -1.15858713  1.49860871  0.38430078  1.07002874  0.12715279\n",
      " -1.75859909  0.29858478  0.55573277 -0.64429116  3.38436059 -0.12999519\n",
      " -1.15858713 -0.81572315  1.07002874  1.15574473  0.55573277 -2.01574707\n",
      " -1.50145111 -1.5871671  -0.21571118  1.24146073 -0.12999519 -0.12999519\n",
      " -0.30142718  0.55573277 -1.33001912  1.5843247  -0.21571118  0.64144876\n",
      " -0.64429116  0.29858478 -0.0442792  -1.50145111  0.38430078 -0.12999519\n",
      " -0.38714317  0.29858478  1.84147269 -0.55857516 -0.90143914  0.55573277\n",
      "  0.0414368  -2.27289506  1.41289271 -2.35861105  0.98431274  0.38430078\n",
      "  0.55573277  0.29858478 -1.50145111 -1.15858713 -0.21571118 -0.30142718\n",
      "  1.07002874  1.32717672 -1.33001912  0.0414368   0.12715279 -1.75859909\n",
      " -1.07287113 -1.50145111  1.32717672 -0.30142718  0.72716476 -2.44432705\n",
      " -0.55857516 -0.0442792   0.21286879  2.09862067 -1.07287113 -1.5871671\n",
      " -0.47285917 -0.0442792  -2.18717906 -0.98715514  0.0414368  -0.21571118\n",
      "  1.49860871  1.24146073  0.29858478  0.38430078 -0.30142718 -0.38714317\n",
      "  2.01290468  0.72716476 -1.93003108 -0.90143914  2.27005266 -0.38714317\n",
      " -0.47285917  1.15574473 -1.24430312 -2.18717906  0.98431274 -0.30142718\n",
      "  0.55573277 -1.07287113  0.38430078  0.47001677  0.64144876  1.07002874\n",
      " -1.33001912 -0.21571118  0.64144876 -1.41573511  0.29858478  0.72716476\n",
      " -0.90143914  0.47001677  0.98431274  1.07002874 -0.98715514 -2.18717906\n",
      "  0.12715279  0.89859675 -0.98715514 -1.50145111  0.12715279 -2.44432705\n",
      "  0.0414368  -0.12999519 -0.47285917 -0.73000715  0.81288075  0.47001677\n",
      " -0.0442792   0.89859675  1.15574473 -1.67288309 -0.64429116  1.15574473\n",
      "  0.47001677 -1.15858713  1.6700407  -0.30142718 -1.07287113 -1.84431508\n",
      " -0.90143914  1.49860871 -1.5871671  -1.33001912  0.72716476 -0.12999519\n",
      " -1.33001912 -0.12999519  1.15574473 -0.47285917  0.98431274  0.64144876\n",
      " -1.50145111  1.24146073 -1.67288309  0.29858478 -0.55857516 -0.30142718\n",
      " -1.50145111  0.72716476  0.72716476  1.24146073 -0.0442792   0.72716476\n",
      " -0.12999519  0.21286879 -0.38714317  1.07002874  1.84147269  1.15574473\n",
      "  0.0414368   1.84147269  1.41289271 -0.81572315 -0.38714317 -1.33001912\n",
      "  0.64144876 -2.18717906 -0.0442792  -0.30142718 -1.41573511 -0.90143914\n",
      "  0.21286879  1.84147269 -1.41573511 -0.73000715 -1.07287113 -1.5871671\n",
      " -0.55857516 -0.55857516 -0.21571118  0.29858478  0.55573277  0.0414368\n",
      "  0.21286879 -0.12999519  1.92718868  0.72716476  0.89859675 -0.12999519\n",
      "  0.29858478 -0.0442792  -0.0442792  -0.12999519 -0.90143914 -0.73000715\n",
      " -0.21571118 -0.21571118 -1.41573511  0.12715279 -0.30142718  3.12721261\n",
      "  0.21286879 -1.24430312 -1.24430312 -0.47285917 -2.10146307 -0.98715514\n",
      "  1.15574473 -1.24430312  0.98431274 -0.55857516 -1.5871671  -1.75859909\n",
      " -0.12999519  1.75575669  0.0414368   2.61291664  1.41289271  0.81288075\n",
      "  1.24146073  1.6700407   0.98431274 -0.12999519  0.89859675 -2.87290702\n",
      " -1.07287113  1.6700407  -0.0442792   1.07002874 -0.30142718 -2.10146307\n",
      " -0.73000715 -1.15858713 -1.15858713  0.47001677 -0.12999519  0.55573277\n",
      " -0.38714317 -0.81572315  2.09862067 -0.30142718 -0.90143914  1.32717672\n",
      "  1.6700407  -0.30142718  0.12715279  0.47001677 -0.38714317 -0.73000715\n",
      "  1.15574473 -2.01574707 -1.24430312  2.09862067 -1.5871671  -0.64429116\n",
      "  0.47001677 -0.30142718  0.0414368  -2.27289506 -1.33001912  1.07002874\n",
      "  2.01290468 -1.41573511 -0.21571118 -0.55857516  1.24146073 -0.38714317\n",
      " -0.47285917  0.12715279 -0.12999519 -0.0442792  -0.12999519  1.84147269\n",
      " -0.21571118  0.0414368   1.6700407  -0.55857516 -0.73000715 -0.55857516\n",
      "  0.98431274 -0.0442792   0.47001677 -0.12999519 -2.01574707  0.98431274\n",
      "  0.38430078  0.55573277 -0.98715514 -3.04433901  1.6700407  -0.90143914\n",
      "  0.0414368  -0.30142718  0.38430078 -0.81572315  0.21286879  0.72716476\n",
      "  0.0414368   0.55573277 -1.07287113 -0.21571118  0.38430078  0.38430078\n",
      "  0.64144876 -1.07287113 -0.21571118 -1.15858713  0.55573277 -0.55857516\n",
      " -1.33001912 -1.50145111  0.12715279 -0.38714317  0.38430078  0.38430078]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test_scaled.iloc[:,0:9] = scaler.transform(X_test_scaled.iloc[:,0:9])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, brier_score_loss, f1_score, fbeta_score, confusion_matrix\n",
    "from tabpfn import TabPFNClassifier\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'\n",
    "\n",
    "np.random.seed(99)\n",
    "\n",
    "# Bootstrap function with ThreadPoolExecutor\n",
    "def bootstrap_metrics(y_true, y_prob, n_bootstraps=1000, random_state=42, max_workers=60):\n",
    "    np.random.seed(random_state)\n",
    "    metrics_list = []\n",
    "    \n",
    "    def compute_metrics(indices):\n",
    "        y_true_boot = y_true.iloc[indices]\n",
    "        y_prob_boot = y_prob[indices]\n",
    "        return evaluate_single_bootstrap(y_true_boot, y_prob_boot)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for _ in range(n_bootstraps):\n",
    "            indices = np.random.choice(len(y_true), len(y_true), replace=True)\n",
    "            futures.append(executor.submit(compute_metrics, indices))\n",
    "        \n",
    "        for future in futures:\n",
    "            metrics_list.append(future.result())\n",
    "    \n",
    "    # Aggregate results\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    mean_metrics = metrics_df.mean()\n",
    "    ci_lower = metrics_df.quantile(0.025)\n",
    "    ci_upper = metrics_df.quantile(0.975)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'Mean': mean_metrics,\n",
    "        'CI Lower': ci_lower,\n",
    "        'CI Upper': ci_upper\n",
    "    })\n",
    "\n",
    "df1 = pd.read_csv('~/data/BAH_PRS/version10/ml_dat/conpass.csv',sep=',',header=0)\n",
    "\n",
    "set1 = ['Age', 'BMI', 'SBP', 'DBP', 'PAC', 'Renin', 'Sex']\n",
    "set2 = ['Age', 'BMI', 'WC', 'TG', 'LDL', 'FBG', 'SBP', 'DBP', 'Renin', 'Sex', 'ASCVD']\n",
    "set3 = ['Age', 'BMI', 'WC', 'TG', 'LDL', 'FBG', 'SBP', 'DBP', 'Sex', 'ASCVD']\n",
    "\n",
    "X = df1[set2]\n",
    "y = df1['IHA']\n",
    "\n",
    "smotenc = SMOTENC(categorical_features=[9,10], \n",
    "                  random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)\n",
    "X_train_resampled, y_train_resampled = smotenc.fit_resample(X_train, y_train)\n",
    "X_train_scaled = X_train_resampled\n",
    "X_test_scaled = X_test\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled.iloc[:,0:9] = scaler.fit_transform(X_train_scaled.iloc[:,0:9])\n",
    "X_test_scaled.iloc[:,0:9] = scaler.transform(X_test_scaled.iloc[:,0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c47c7f-5ddb-4b64-83a5-775a32f3faad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TabPFNClassifier(balance_probabilities=True, device=&#x27;cpu&#x27;, n_estimators=32,\n",
       "                 random_state=42, softmax_temperature=0.6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TabPFNClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TabPFNClassifier(balance_probabilities=True, device=&#x27;cpu&#x27;, n_estimators=32,\n",
       "                 random_state=42, softmax_temperature=0.6)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TabPFNClassifier(balance_probabilities=True, device='cpu', n_estimators=32,\n",
       "                 random_state=42, softmax_temperature=0.6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>CI Lower</th>\n",
       "      <th>CI Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.864354</td>\n",
       "      <td>0.824492</td>\n",
       "      <td>0.899406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.849292</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.876984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.302396</td>\n",
       "      <td>0.205463</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.961913</td>\n",
       "      <td>0.942854</td>\n",
       "      <td>0.978873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>0.620970</td>\n",
       "      <td>0.461486</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>0.870053</td>\n",
       "      <td>0.838771</td>\n",
       "      <td>0.897162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR+</th>\n",
       "      <td>8.529386</td>\n",
       "      <td>4.517439</td>\n",
       "      <td>15.677344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR-</th>\n",
       "      <td>0.725309</td>\n",
       "      <td>0.621415</td>\n",
       "      <td>0.827289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOR</th>\n",
       "      <td>11.996015</td>\n",
       "      <td>5.548310</td>\n",
       "      <td>23.393212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.404904</td>\n",
       "      <td>0.294482</td>\n",
       "      <td>0.510949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>0.336305</td>\n",
       "      <td>0.234364</td>\n",
       "      <td>0.438602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brier Score</th>\n",
       "      <td>0.116088</td>\n",
       "      <td>0.095106</td>\n",
       "      <td>0.139842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Mean  CI Lower   CI Upper\n",
       "AUC           0.864354  0.824492   0.899406\n",
       "Accuracy      0.849292  0.817460   0.876984\n",
       "Sensitivity   0.302396  0.205463   0.400000\n",
       "Specificity   0.961913  0.942854   0.978873\n",
       "PPV           0.620970  0.461486   0.763158\n",
       "NPV           0.870053  0.838771   0.897162\n",
       "LR+           8.529386  4.517439  15.677344\n",
       "LR-           0.725309  0.621415   0.827289\n",
       "DOR          11.996015  5.548310  23.393212\n",
       "F1            0.404904  0.294482   0.510949\n",
       "F2            0.336305  0.234364   0.438602\n",
       "Brier Score   0.116088  0.095106   0.139842"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define evaluation metrics\n",
    "def evaluate_single_bootstrap(y_true_boot, y_prob_boot):\n",
    "    y_pred_boot = (y_prob_boot > 0.5).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true_boot, y_pred_boot).ravel()\n",
    "    \n",
    "    return {\n",
    "        'AUC': roc_auc_score(y_true_boot, y_prob_boot),\n",
    "        'Accuracy': accuracy_score(y_true_boot, y_pred_boot),\n",
    "        'Sensitivity': tp / (tp + fn) if (tp + fn) != 0 else 0,\n",
    "        'Specificity': tn / (tn + fp) if (tn + fp) != 0 else 0,\n",
    "        'PPV': tp / (tp + fp) if (tp + fp) != 0 else 0,\n",
    "        'NPV': tn / (tn + fn) if (tn + fn) != 0 else 0,\n",
    "        'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
    "        'LR-': (1 - (tp / (tp + fn))) / (tn / (tn + fp)) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
    "        'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
    "                if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
    "        'F1': f1_score(y_true_boot, y_pred_boot),\n",
    "        'F2': fbeta_score(y_true_boot, y_pred_boot, beta=2),\n",
    "        'Brier Score': brier_score_loss(y_true_boot, y_prob_boot)\n",
    "    }\n",
    "    \n",
    "# Train TabPFN model\n",
    "model = TabPFNClassifier(n_estimators=32, device='cpu', random_state=42, softmax_temperature=0.6, balance_probabilities=True)\n",
    "model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "results_df1 = bootstrap_metrics(y_test, y_prob)\n",
    "results_df1\n",
    "# Save probabilities\n",
    "pd.DataFrame(y_prob, columns=['Probability']).to_csv('/home/luo_wenjin/data/BAH_PRS/version10/ml_dat/prob_model2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44489575-1041-4ab7-9b09-dcd36c4ed0e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_456912/728613764.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.98698266 -0.80089916 -1.17729534  0.61058649  0.89288362 -1.08319629\n",
      "  0.70468553 -0.51860203  0.32828936 -0.42450299 -0.98909725  0.89288362\n",
      " -0.04810681 -0.42450299 -0.14220586 -0.33040394 -1.17729534 -1.17729534\n",
      " -2.30648386  0.51648745 -1.55369151 -0.80089916  0.23419032  0.98698266\n",
      "  1.08108171 -1.45959247  1.17518075 -2.11828577 -0.33040394  0.70468553\n",
      "  0.51648745 -2.4005829  -0.89499821 -1.08319629 -0.04810681 -0.14220586\n",
      "  0.23419032  0.61058649  0.70468553  0.14009127 -1.08319629  0.70468553\n",
      " -0.70680012 -0.14220586 -0.33040394  0.14009127  0.61058649 -0.33040394\n",
      " -0.51860203 -1.27139438  1.17518075 -0.42450299  0.51648745  0.04599223\n",
      " -0.42450299  1.36337884  0.32828936 -0.14220586  0.32828936  0.32828936\n",
      "  1.17518075 -1.08319629  1.17518075 -0.51860203  0.79878458  0.98698266\n",
      " -0.70680012  0.4223884   1.08108171  0.14009127 -0.51860203 -0.14220586\n",
      "  1.08108171  0.23419032 -0.42450299 -0.98909725 -1.45959247 -0.04810681\n",
      "  0.14009127  0.04599223  0.14009127 -0.33040394 -0.70680012  0.04599223\n",
      " -0.70680012 -0.14220586  0.70468553  1.26927979 -1.27139438 -1.36549342\n",
      " -0.14220586  0.89288362 -0.33040394 -1.83598864  1.26927979  0.98698266\n",
      " -0.42450299  0.32828936 -0.33040394 -1.17729534 -0.2363049   1.45747788\n",
      "  1.17518075  0.4223884   0.4223884   0.79878458 -0.04810681 -0.2363049\n",
      "  0.32828936  0.98698266  0.98698266 -3.52977142 -0.33040394 -0.2363049\n",
      "  0.4223884   0.98698266  1.73977501 -1.08319629  0.51648745  0.14009127\n",
      " -0.33040394  0.61058649  0.61058649 -3.24747429  1.45747788  0.32828936\n",
      " -0.14220586 -0.70680012 -0.70680012 -0.42450299 -2.49468194  1.17518075\n",
      "  0.98698266 -1.64779055  1.26927979  0.61058649 -0.33040394 -0.98909725\n",
      "  1.26927979 -0.70680012 -0.51860203  1.36337884  0.79878458  0.98698266\n",
      "  2.02207214  0.04599223  0.79878458  0.61058649  1.45747788  0.89288362\n",
      " -1.36549342  1.08108171  0.70468553 -1.08319629  1.17518075 -1.27139438\n",
      "  0.14009127 -1.55369151  0.70468553  0.79878458  0.98698266  1.08108171\n",
      "  0.98698266 -1.7418896   0.4223884   1.45747788  0.89288362 -1.64779055\n",
      " -1.55369151  0.51648745 -0.51860203 -0.42450299  1.64567597 -1.27139438\n",
      "  0.04599223  1.08108171 -0.51860203  1.17518075]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:9] = scaler.fit_transform(X_val.iloc[:, 0:9])\n",
      "/tmp/ipykernel_456912/728613764.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.58078406  0.08678041  0.26231351  0.17454696 -0.615352    2.28094419\n",
      "  1.13997902 -0.615352   -1.14195131 -1.22971786  1.40327868  2.28094419\n",
      "  0.35008006 -0.52758545  0.08678041  0.52561317  0.78891282  0.43784661\n",
      " -0.08875269  0.52561317 -0.52758545 -1.58078406  1.40327868 -0.17651924\n",
      "  1.49104523 -0.615352   -0.70311855  0.70114627  0.52561317  0.52561317\n",
      "  1.57881178  0.26231351 -1.05418476  2.28094419  0.43784661  0.52561317\n",
      "  0.52561317 -1.14195131  0.43784661 -1.75631716  1.40327868  0.08678041\n",
      "  0.08678041  0.26231351  2.28094419 -1.58078406  0.08678041  0.08678041\n",
      "  0.70114627  1.57881178 -0.52758545  1.40327868  0.61337972  0.08678041\n",
      "  0.70114627  0.35008006  0.35008006  0.52561317 -0.52758545  0.08678041\n",
      "  0.08678041 -0.7908851   0.52561317  0.08678041  1.57881178  0.78891282\n",
      "  0.26231351  0.52561317 -0.35205235  0.87667937 -0.17651924 -1.58078406\n",
      "  0.08678041 -1.58078406  1.49104523 -0.35205235 -0.52758545  0.78891282\n",
      " -0.7908851   0.17454696 -0.615352    1.57881178  0.87667937  0.26231351\n",
      " -1.84408372 -1.58078406  0.78891282  0.08678041  0.26231351  0.43784661\n",
      "  0.08678041 -0.87865165 -0.26428579 -1.58078406  0.08678041  2.28094419\n",
      " -1.75631716 -0.52758545 -0.4398189  -1.75631716 -2.89728233 -0.52758545\n",
      " -0.7908851  -1.66855061  1.57881178  0.26231351 -0.08875269  0.08678041\n",
      " -1.14195131 -1.14195131 -0.35205235 -1.75631716  0.43784661  0.26231351\n",
      "  0.87667937 -1.84408372 -0.08875269 -0.52758545 -1.84408372  2.28094419\n",
      " -0.615352   -2.89728233  0.08678041  0.43784661  0.26231351 -1.84408372\n",
      "  0.35008006  0.17454696 -0.52758545  0.43784661  0.17454696  0.08678041\n",
      "  1.57881178  1.40327868 -0.35205235  0.61337972  0.35008006  0.43784661\n",
      " -0.9664182   0.70114627 -0.87865165  0.08678041  0.87667937 -0.615352\n",
      " -0.4398189   0.70114627  0.08678041 -0.35205235  0.08678041  0.08678041\n",
      "  0.08678041  0.43784661 -0.7908851  -0.70311855  0.43784661  0.87667937\n",
      "  0.08678041 -1.58078406 -0.52758545 -1.75631716 -0.87865165 -0.7908851\n",
      "  0.70114627  0.17454696  1.49104523  1.57881178  0.35008006 -1.22971786\n",
      "  0.78891282  0.43784661 -0.52758545  0.08678041  0.26231351 -1.14195131\n",
      " -0.52758545  0.26231351  0.35008006 -0.9664182 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:9] = scaler.fit_transform(X_val.iloc[:, 0:9])\n",
      "/tmp/ipykernel_456912/728613764.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.71503218 -0.85828245  1.52881562 -1.23804805  0.82353664 -0.31576016\n",
      " -0.04449902  1.20330224  2.55960796 -1.78057034  0.76928441  1.09479779\n",
      " -1.02103914  0.00975321  0.71503218 -0.26150793 -1.67206588  0.9320411\n",
      " -0.15300348 -0.42426462 -0.37001239  0.87778887 -0.20725571  2.01708567\n",
      "  0.28101435 -0.26150793 -0.42426462 -1.07529137  2.23409459 -0.09875125\n",
      "  0.22676212 -0.26150793  0.00975321 -0.85828245  1.85432899  1.36605893\n",
      "  1.04054556  1.80007676  3.15638248 -0.20725571 -0.42426462  0.9320411\n",
      "  0.60652773  0.33526658  2.93937356 -0.37001239  0.71503218  0.06400544\n",
      " -0.69552576  0.60652773  1.14905001 -0.64127354  0.1725099  -0.09875125\n",
      "  0.71503218 -0.37001239 -2.05183148 -1.29230028  0.5522755   0.38951881\n",
      "  2.4511035   0.00975321 -1.67206588  1.14905001 -0.09875125 -0.37001239\n",
      "  0.9320411   0.71503218  0.60652773  0.00975321  0.76928441  0.60652773\n",
      " -2.05183148 -0.80403022  1.14905001  0.11825767 -0.04449902  2.50535573\n",
      " -0.69552576  1.6915723   0.11825767 -1.07529137  0.49802327 -0.42426462\n",
      " -1.34655251 -0.26150793  0.60652773  1.3118067  -0.58702131  0.87778887\n",
      "  0.28101435 -0.80403022  0.00975321 -0.64127354  0.00975321  0.00975321\n",
      " -0.91253468 -0.53276908  0.76928441  0.28101435 -0.42426462  1.58306784\n",
      " -0.42426462 -0.85828245  0.00975321 -0.80403022 -0.80403022  1.36605893\n",
      " -0.20725571 -0.26150793  1.25755447 -1.56356142 -0.42426462  0.00975321\n",
      " -1.07529137  0.1725099   1.63732007 -1.83482257  0.11825767  0.11825767\n",
      " -0.37001239 -1.02103914 -0.04449902 -1.29230028 -0.58702131 -0.91253468\n",
      " -1.18379582  0.33526658 -0.37001239 -0.91253468 -1.12954359 -0.15300348\n",
      " -0.85828245 -0.64127354 -1.07529137 -0.91253468 -0.53276908  0.33526658\n",
      "  0.5522755  -0.26150793 -1.29230028  0.66077995  0.00975321  0.76928441\n",
      "  1.09479779 -1.83482257  0.38951881 -1.23804805  1.6915723  -0.26150793\n",
      "  0.44377104  0.11825767 -1.67206588 -0.58702131 -0.04449902 -1.07529137\n",
      " -1.12954359 -1.78057034 -0.31576016 -1.07529137  0.49802327  0.66077995\n",
      " -1.02103914 -1.23804805  0.82353664  0.06400544  0.49802327 -1.29230028\n",
      " -1.23804805 -0.91253468  0.00975321 -0.69552576  0.5522755   0.5522755\n",
      "  1.09479779 -0.26150793  0.28101435  0.11825767]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:9] = scaler.fit_transform(X_val.iloc[:, 0:9])\n",
      "/tmp/ipykernel_456912/728613764.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.49558123 -0.60076195  1.92926077 -0.09475741  0.24257896 -0.51642786\n",
      "  0.83291759  0.32691305  1.25458805 -1.0224324  -0.60076195  0.66424941\n",
      " -0.60076195 -0.01042331  1.00158577  0.49558123  0.7485835   0.49558123\n",
      "  1.42325623  0.24257896 -0.01042331  0.49558123  0.32691305  0.15824487\n",
      " -1.27543468  1.08591987 -0.51642786 -0.60076195  1.6762585  -0.43209377\n",
      "  0.24257896 -0.60076195  0.66424941  1.42325623  1.00158577  0.41124714\n",
      " -0.01042331  0.24257896  1.25458805 -0.93809831  0.49558123 -0.85376422\n",
      "  1.50759032  0.91725168  3.78461077 -0.68509604 -0.43209377  0.91725168\n",
      " -0.43209377  0.24257896 -1.10676649 -0.26342559  0.91725168 -0.43209377\n",
      "  2.51959941  0.07391078 -2.20310968 -1.27543468  0.24257896 -0.01042331\n",
      "  0.32691305  0.24257896 -1.19110059  0.7485835  -0.93809831 -1.27543468\n",
      "  1.08591987  1.00158577 -0.1790915   0.24257896  0.41124714 -0.34775968\n",
      " -2.11877558 -0.43209377 -0.09475741 -0.09475741 -0.51642786  1.92926077\n",
      "  0.15824487  2.01359486  0.49558123 -0.1790915   1.92926077  0.91725168\n",
      "  0.7485835  -0.1790915  -0.34775968 -2.20310968  0.32691305  1.17025396\n",
      "  0.41124714 -1.86577331 -0.01042331  2.01359486  0.49558123  0.24257896\n",
      " -0.85376422 -0.09475741  0.15824487  0.83291759  0.24257896  1.25458805\n",
      "  0.07391078 -1.44410286  1.92926077  0.32691305  0.57991532  1.08591987\n",
      "  0.41124714 -0.34775968 -0.01042331 -1.78143922  1.25458805 -1.27543468\n",
      "  0.57991532 -1.10676649  1.08591987 -0.51642786 -0.43209377  0.57991532\n",
      "  1.08591987 -0.60076195  0.32691305 -1.19110059  1.00158577 -0.34775968\n",
      " -0.34775968  0.41124714  0.07391078 -1.10676649  0.49558123 -1.44410286\n",
      " -0.93809831  0.49558123  0.57991532 -1.10676649  0.32691305  0.57991532\n",
      " -1.27543468 -0.26342559  0.24257896 -2.79344831 -0.34775968  0.32691305\n",
      " -1.61277104 -0.26342559 -0.34775968 -0.93809831 -0.68509604 -1.61277104\n",
      " -0.51642786  0.24257896 -2.03444149 -0.09475741 -2.11877558 -0.68509604\n",
      " -0.1790915  -0.68509604 -0.1790915  -0.60076195 -1.10676649  1.42325623\n",
      " -1.10676649 -0.93809831  0.7485835  -2.45611195 -0.68509604 -0.93809831\n",
      "  0.07391078 -1.0224324  -0.34775968  0.32691305  0.49558123 -0.76943013\n",
      " -0.09475741  0.07391078  1.25458805  0.49558123]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:9] = scaler.fit_transform(X_val.iloc[:, 0:9])\n",
      "/tmp/ipykernel_456912/728613764.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.21033902 -1.09494631  0.13355753 -0.48069439  0.21033902 -0.4039129\n",
      " -0.86460184  1.13171689  0.363902    2.05309477  1.66918732  0.05677604\n",
      "  0.51746497 -0.17356843 -0.25034992 -1.01816482 -2.32345014 -0.63425737\n",
      "  0.51746497  0.59424646 -0.32713141  0.21033902  0.28712051 -0.32713141\n",
      "  1.0549354   0.28712051 -1.1717278   0.59424646  0.97815391  0.21033902\n",
      "  0.74780944 -0.17356843 -1.8627612   1.36206136  1.20849838 -0.17356843\n",
      "  1.59240583 -0.86460184 -0.71103886 -0.86460184 -0.09678694  0.28712051\n",
      " -0.32713141  0.28712051 -1.78597971 -1.01816482 -2.01632418  1.59240583\n",
      " -2.09310567  0.363902   -1.24850929  0.51746497 -0.55747588  0.67102795\n",
      " -2.09310567  0.74780944 -0.48069439 -0.25034992 -0.48069439 -0.32713141\n",
      "  0.97815391  1.28527987 -0.09678694 -0.32713141  0.05677604 -0.63425737\n",
      "  0.90137242  1.43884285  0.05677604 -0.4039129  -0.94138333  0.90137242\n",
      "  0.74780944  0.59424646 -0.32713141 -1.47885375  0.67102795 -0.78782035\n",
      " -1.09494631 -0.48069439 -0.86460184  1.13171689 -0.63425737  0.44068349\n",
      "  1.13171689 -1.47885375  0.363902   -0.78782035 -0.94138333  0.363902\n",
      " -2.01632418  0.21033902  1.28527987 -0.48069439  0.28712051 -0.32713141\n",
      " -0.32713141  0.97815391 -0.48069439 -1.47885375 -1.70919822 -0.48069439\n",
      " -0.63425737  0.82459093  0.51746497 -1.24850929  1.43884285  1.28527987\n",
      "  0.28712051  0.97815391  0.97815391 -0.94138333 -1.01816482 -1.70919822\n",
      " -0.63425737  0.82459093 -0.17356843  0.13355753 -1.8627612  -0.94138333\n",
      " -1.63241673  1.0549354   0.74780944 -2.24666865 -0.09678694  0.51746497\n",
      "  0.67102795  0.90137242 -1.40207227  0.363902   -1.09494631  0.82459093\n",
      "  0.44068349 -1.32529078 -1.32529078 -0.71103886 -0.17356843 -0.02000545\n",
      " -0.09678694 -1.24850929  0.59424646 -0.48069439  1.43884285  1.51562434\n",
      " -0.94138333  1.0549354   0.13355753 -0.09678694 -0.17356843  0.28712051\n",
      " -0.78782035 -0.94138333 -0.94138333 -1.32529078  0.82459093  0.97815391\n",
      " -0.63425737  0.363902   -0.17356843 -1.09494631  0.44068349 -0.63425737\n",
      " -0.02000545 -1.78597971  0.82459093  0.363902    0.74780944  0.05677604\n",
      " -1.01816482 -1.93954269  0.28712051  1.36206136  0.21033902 -1.93954269\n",
      " -1.1717278  -1.47885375 -0.63425737 -0.32713141  0.363902    0.05677604\n",
      "  0.67102795 -1.1717278   0.59424646 -0.71103886  0.59424646 -0.63425737\n",
      " -0.55747588  0.28712051  0.363902    1.36206136 -1.01816482  1.59240583\n",
      "  0.82459093  1.0549354  -0.94138333 -0.78782035 -0.32713141 -1.78597971\n",
      " -1.8627612   0.90137242 -1.1717278  -0.4039129   0.13355753  0.51746497\n",
      " -0.4039129   0.59424646  0.59424646 -1.01816482  1.97631328  0.363902\n",
      "  0.59424646 -2.01632418 -0.09678694 -0.02000545  0.363902    1.28527987\n",
      "  0.67102795 -0.55747588 -0.55747588  1.20849838  0.44068349 -1.01816482\n",
      " -0.17356843 -0.25034992  1.74596881 -0.4039129   1.0549354  -0.02000545\n",
      " -2.09310567  0.363902    2.12987626  0.59424646 -0.02000545  0.51746497\n",
      "  0.74780944  0.28712051 -2.47701312 -1.01816482  2.05309477  0.67102795\n",
      "  0.44068349 -0.55747588 -1.40207227 -0.71103886 -0.48069439  1.36206136\n",
      "  0.51746497  0.44068349  0.21033902 -0.17356843  0.05677604 -0.78782035\n",
      "  1.13171689 -0.48069439 -1.70919822  2.89769115 -0.17356843 -0.78782035\n",
      "  1.36206136 -0.02000545  0.59424646  0.05677604 -0.78782035 -0.71103886\n",
      "  0.82459093  0.59424646 -0.4039129  -0.94138333  0.82459093  0.74780944\n",
      "  1.97631328  0.51746497  0.90137242 -1.47885375 -0.48069439  0.28712051\n",
      " -0.09678694 -2.16988716  0.21033902  1.43884285  1.43884285  0.13355753\n",
      "  0.13355753  0.21033902  1.20849838 -2.32345014  0.363902    0.13355753\n",
      " -1.8627612  -0.4039129   0.21033902 -0.48069439  0.363902    1.28527987\n",
      "  0.74780944 -1.32529078 -1.47885375  0.05677604  0.82459093  0.82459093\n",
      "  0.59424646  0.05677604  0.363902   -0.55747588 -0.09678694 -0.4039129\n",
      " -0.09678694 -1.1717278  -0.32713141  1.66918732 -1.55563524 -1.01816482\n",
      " -0.94138333 -0.86460184  0.44068349 -1.1717278  -0.32713141 -1.09494631\n",
      " -0.09678694 -1.78597971 -0.48069439  0.05677604 -0.09678694  1.13171689\n",
      "  1.74596881 -0.48069439 -0.94138333  0.59424646 -1.40207227  1.0549354\n",
      " -0.48069439  0.05677604 -1.24850929 -1.32529078  0.67102795  1.13171689\n",
      " -0.71103886 -0.48069439 -1.1717278   1.13171689  1.28527987  1.20849838\n",
      "  0.363902   -0.09678694  1.36206136  1.51562434  1.0549354  -1.1717278\n",
      "  0.67102795  2.05309477  0.44068349 -0.48069439 -1.47885375  0.05677604\n",
      " -0.32713141  1.0549354   0.13355753  0.82459093  2.12987626  2.12987626\n",
      "  1.20849838  1.36206136  0.05677604 -1.1717278  -0.02000545 -1.47885375\n",
      " -0.25034992 -0.02000545 -0.94138333  0.97815391 -0.17356843 -0.02000545\n",
      " -0.55747588  1.0549354  -0.17356843 -1.24850929 -0.4039129   0.05677604\n",
      "  1.13171689 -1.1717278   1.0549354  -1.78597971 -1.55563524  0.74780944\n",
      "  0.82459093 -0.25034992  1.36206136 -1.01816482  2.05309477 -0.86460184\n",
      "  0.05677604  0.51746497 -0.17356843  1.66918732  0.363902    0.363902\n",
      "  0.90137242 -0.94138333  1.36206136  0.13355753  0.21033902 -2.47701312\n",
      "  1.28527987  1.43884285  1.59240583 -0.09678694  0.363902    1.43884285\n",
      "  1.51562434  0.97815391 -1.32529078  0.13355753 -0.63425737  0.59424646\n",
      " -0.94138333  1.43884285 -0.86460184  1.28527987 -1.40207227  1.43884285\n",
      "  0.05677604  0.90137242  1.66918732  0.82459093 -0.71103886 -0.09678694\n",
      " -1.40207227  0.28712051  1.43884285  0.21033902  1.28527987 -0.32713141\n",
      " -0.55747588  0.05677604 -0.32713141 -1.24850929  2.12987626  1.13171689\n",
      "  0.05677604  0.90137242 -0.09678694  1.89953179  0.59424646 -1.09494631\n",
      " -0.09678694  1.20849838 -0.63425737 -0.55747588 -0.71103886  0.97815391\n",
      " -0.09678694 -0.55747588 -1.09494631  0.13355753  0.05677604  0.363902\n",
      "  0.97815391 -0.48069439  0.05677604  0.67102795 -0.4039129   0.21033902\n",
      "  0.51746497  1.97631328 -0.71103886 -0.4039129   2.05309477 -1.47885375\n",
      "  0.74780944  0.51746497  1.20849838  0.44068349  1.8227503   1.0549354\n",
      "  0.05677604 -2.47701312  1.36206136  1.43884285  1.8227503   1.66918732\n",
      "  0.21033902 -1.47885375  0.44068349  0.51746497 -1.70919822  0.363902\n",
      "  0.97815391 -2.55379461  0.44068349 -0.25034992  2.5137837  -0.78782035\n",
      "  0.90137242 -0.94138333  1.43884285  0.21033902 -0.09678694 -1.63241673\n",
      "  0.82459093 -0.78782035 -0.55747588 -0.32713141  0.05677604 -2.47701312\n",
      "  0.363902   -0.4039129   0.05677604 -1.47885375  0.97815391  0.67102795\n",
      "  1.28527987 -0.32713141 -0.48069439  0.44068349  0.67102795  0.13355753\n",
      " -1.55563524 -0.17356843  0.59424646 -1.01816482 -0.48069439  0.363902\n",
      "  0.90137242 -0.25034992 -0.55747588  0.21033902 -0.48069439 -1.24850929\n",
      " -0.78782035 -0.09678694 -0.71103886  0.05677604 -0.48069439 -0.17356843\n",
      " -1.24850929 -0.78782035  0.05677604 -1.24850929 -0.09678694 -0.55747588\n",
      "  0.21033902 -0.55747588  0.90137242  0.13355753 -1.01816482]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:9] = scaler.fit_transform(X_val.iloc[:, 0:9])\n",
      "/tmp/ipykernel_456912/728613764.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.4790469  -0.12592865  0.61348591  0.00851036  0.54626641 -0.52924569\n",
      " -1.94085531 -1.06700173  0.27738838  1.15124196 -0.05870915  1.01680294\n",
      "  0.00851036 -0.19314816  0.34460789  0.07572987 -0.7309042  -0.26036766\n",
      " -0.26036766 -0.39480667 -0.39480667  0.00851036  0.00851036 -0.46202618\n",
      " -0.19314816  0.00851036  0.41182739  0.34460789  2.42841256  1.28568097\n",
      "  1.42011998  0.68070542 -0.46202618 -1.94085531 -1.33587975  0.14294937\n",
      "  0.68070542 -0.86534321 -0.6636847   0.88236393  0.4790469  -0.99978223\n",
      " -1.06700173  0.81514443 -1.53753827 -1.67197728 -1.47031877 -2.00807481\n",
      " -2.07529432 -1.33587975 -0.99978223  0.34460789 -1.20144074  1.08402245\n",
      " -0.26036766  0.14294937 -0.12592865 -2.00807481  0.68070542  0.07572987\n",
      " -0.19314816 -0.86534321  0.14294937  1.75621751  2.29397355  0.00851036\n",
      "  0.81514443 -0.32758717 -0.46202618  0.00851036 -0.19314816  1.28568097\n",
      " -0.26036766 -0.12592865 -1.8736358   0.54626641  0.68070542  1.75621751\n",
      " -0.93256272  0.21016888 -0.26036766 -1.26866025 -1.06700173  0.00851036\n",
      " -0.46202618 -0.39480667 -0.05870915 -0.12592865  0.94958344 -0.52924569\n",
      " -0.6636847   0.81514443  0.81514443 -1.26866025 -0.6636847  -0.19314816\n",
      " -0.39480667 -0.93256272 -0.86534321  0.14294937 -0.26036766 -1.8736358\n",
      "  0.54626641  0.81514443  1.08402245 -0.7309042   0.4790469   0.14294937\n",
      "  1.55455899 -0.99978223  0.94958344 -0.32758717 -0.93256272 -0.6636847\n",
      " -0.6636847   0.81514443  0.74792492 -1.33587975 -1.06700173 -0.6636847\n",
      " -0.39480667 -0.39480667  0.61348591 -0.26036766 -0.32758717 -0.05870915\n",
      " -0.26036766  2.8317296  -2.07529432  0.21016888  0.81514443 -0.99978223\n",
      " -0.79812371 -1.8736358   2.29397355 -0.26036766  1.55455899 -2.00807481\n",
      "  0.14294937 -0.32758717 -1.73919679 -0.52924569 -2.00807481  0.94958344\n",
      " -1.06700173  0.41182739 -0.32758717  1.6217785   0.88236393  1.15124196\n",
      " -1.33587975 -1.26866025  0.00851036  0.61348591 -0.79812371 -0.26036766\n",
      " -1.53753827 -1.47031877 -1.33587975  0.81514443  0.88236393 -0.6636847\n",
      "  1.75621751  1.688998   -1.13422124 -0.46202618  0.14294937 -0.46202618\n",
      " -0.39480667  0.14294937  2.29397355 -0.26036766 -0.05870915 -1.26866025\n",
      " -0.46202618  1.28568097 -2.07529432 -1.47031877  2.63007108 -0.46202618\n",
      " -0.05870915 -0.46202618 -0.7309042  -0.26036766  0.74792492  2.09231504\n",
      "  1.01680294  0.88236393 -0.6636847  -1.40309926  0.54626641  0.68070542\n",
      " -0.26036766  0.14294937  0.14294937 -0.05870915 -2.00807481 -1.8736358\n",
      "  0.61348591  0.21016888 -0.12592865 -1.26866025 -0.39480667 -0.7309042\n",
      " -1.60475778  0.41182739 -0.19314816  1.75621751 -0.6636847   0.54626641\n",
      "  0.94958344  0.21016888 -1.20144074 -0.7309042   0.68070542 -0.86534321\n",
      "  0.94958344 -1.13422124 -0.19314816 -0.52924569  1.08402245 -0.19314816\n",
      " -1.33587975 -1.8736358   0.68070542  1.15124196 -2.07529432  1.08402245\n",
      " -1.13422124 -0.79812371  0.07572987  0.81514443  1.21846146 -0.32758717\n",
      "  0.41182739 -1.26866025  0.27738838  0.4790469  -0.12592865  1.75621751\n",
      " -0.26036766 -0.86534321 -1.33587975 -0.32758717  0.81514443 -0.26036766\n",
      " -0.86534321  1.48733948  1.01680294  2.49563207  0.61348591 -0.59646519\n",
      " -1.06700173  1.95787602  1.688998   -0.39480667 -0.99978223 -0.26036766\n",
      "  1.01680294  0.14294937 -0.86534321  0.41182739  0.14294937  1.75621751\n",
      "  2.8989491  -0.05870915  0.27738838 -0.12592865  1.82343701 -0.59646519\n",
      " -0.39480667  1.75621751  0.81514443 -0.93256272  1.55455899  0.61348591\n",
      " -0.79812371  0.94958344 -0.6636847  -0.59646519  1.55455899  0.14294937\n",
      "  2.29397355 -0.46202618 -0.19314816  0.4790469   1.01680294 -0.12592865\n",
      "  1.28568097  2.56285158  0.61348591  0.81514443  2.02509553  0.27738838\n",
      "  1.688998    1.01680294 -0.59646519  1.01680294 -0.86534321 -0.99978223\n",
      "  0.07572987 -0.86534321  0.94958344  0.4790469   0.34460789 -0.05870915\n",
      "  0.14294937 -2.00807481 -0.26036766 -0.7309042   0.14294937  0.68070542\n",
      "  0.88236393 -0.86534321 -0.6636847  -1.20144074 -1.06700173 -0.12592865\n",
      "  0.88236393 -0.6636847   1.21846146  0.74792492 -0.19314816 -0.05870915\n",
      "  1.688998    0.61348591  0.81514443 -0.6636847   0.74792492  1.15124196\n",
      " -0.12592865  1.08402245 -1.60475778  2.02509553  0.00851036  0.94958344\n",
      " -0.79812371 -1.47031877 -1.60475778 -0.7309042  -0.19314816 -1.20144074\n",
      " -0.12592865  0.07572987 -1.20144074 -0.6636847  -0.59646519 -1.33587975\n",
      " -0.12592865 -0.19314816  0.61348591  2.63007108 -0.19314816 -0.7309042\n",
      " -0.39480667 -0.26036766 -0.52924569 -1.60475778 -0.39480667 -0.26036766\n",
      "  0.41182739  0.61348591 -1.20144074 -0.32758717  1.01680294  1.28568097\n",
      "  1.82343701 -0.12592865 -0.12592865  1.35290047 -0.26036766  0.68070542\n",
      " -0.12592865  0.14294937 -0.39480667  2.15953454  1.35290047 -2.07529432\n",
      " -0.6636847   0.61348591  0.74792492 -1.26866025 -0.19314816  0.00851036\n",
      "  0.07572987 -1.26866025 -0.26036766 -0.79812371 -0.99978223 -1.33587975\n",
      " -1.26866025 -0.26036766 -0.6636847  -0.99978223  2.15953454 -0.19314816\n",
      " -0.46202618 -0.26036766 -1.26866025  0.74792492 -0.39480667 -0.19314816\n",
      " -0.26036766  0.4790469  -0.26036766  1.28568097  1.42011998 -0.7309042\n",
      "  1.35290047  0.61348591  0.88236393  1.21846146 -0.7309042   0.27738838\n",
      " -0.86534321  0.88236393 -0.6636847  -0.93256272  0.21016888 -1.8736358\n",
      "  0.68070542  0.14294937  0.68070542 -0.59646519 -1.73919679  0.68070542\n",
      " -1.60475778  0.00851036 -0.39480667  1.95787602 -0.26036766  0.14294937\n",
      " -0.6636847   0.4790469   1.28568097  0.21016888 -0.7309042  -0.79812371\n",
      " -1.20144074  0.81514443 -1.33587975  2.63007108 -0.79812371 -0.26036766\n",
      "  0.54626641 -0.39480667 -1.26866025 -1.20144074 -1.33587975  0.4790469\n",
      "  2.02509553 -0.59646519 -0.39480667 -0.19314816  1.08402245 -0.52924569\n",
      " -0.46202618 -1.20144074  0.41182739  0.88236393 -0.6636847   0.81514443\n",
      "  0.41182739  1.48733948  0.07572987 -1.60475778 -0.05870915  1.01680294\n",
      "  0.94958344 -1.33587975  0.81514443 -0.59646519  0.00851036  0.07572987\n",
      "  0.14294937  2.22675405 -1.47031877  0.34460789  2.09231504 -0.93256272\n",
      "  0.34460789 -1.20144074 -0.7309042   0.74792492  0.54626641  1.28568097\n",
      "  0.68070542 -2.07529432 -0.39480667 -0.79812371 -0.26036766 -0.26036766\n",
      " -0.12592865 -0.26036766  0.00851036  0.4790469   0.81514443  0.00851036\n",
      "  0.61348591 -0.19314816  0.68070542 -0.19314816  0.74792492  0.34460789\n",
      "  0.54626641 -0.7309042   0.21016888  0.00851036  0.14294937 -0.05870915\n",
      "  0.88236393  1.01680294 -0.26036766  0.4790469   0.34460789  2.02509553\n",
      " -0.05870915  1.688998    0.61348591 -0.79812371 -0.39480667 -0.39480667\n",
      " -0.39480667  0.61348591  0.4790469  -0.39480667 -1.13422124 -0.05870915\n",
      "  0.74792492  1.95787602  0.14294937 -0.12592865  0.07572987 -0.12592865\n",
      "  0.34460789 -1.26866025  0.68070542 -0.12592865  0.74792492 -1.47031877\n",
      "  1.35290047  1.28568097 -0.46202618  0.94958344 -0.86534321]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:9] = scaler.fit_transform(X_val.iloc[:, 0:9])\n",
      "/tmp/ipykernel_456912/728613764.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.10510069  0.82226051  1.95362122 -1.49702895  1.55764497  0.82226051\n",
      " -0.81821252  0.87882855  1.4445089  -0.1393961   1.16166872  1.16166872\n",
      " -0.36566824  0.99196462  1.16166872 -0.81821252 -0.47880431  1.04853265\n",
      "  0.70912444  0.87882855  0.59598837 -0.02626002 -0.81821252 -1.72330109\n",
      " -0.08282806  1.16166872  1.33137283  0.08687605 -0.02626002  1.61421301\n",
      " -1.1010527  -1.44046091 -0.76164449  0.36971623  2.01018926  1.84048515\n",
      " -0.70507645 -0.98791663 -1.83643716 -0.3091002   1.95362122 -1.1010527\n",
      " -0.25253217  0.53942033 -0.70507645 -1.21418877  0.25658015 -1.21418877\n",
      " -2.23241341  0.36971623 -0.59194038  0.4828523  -0.42223627 -0.59194038\n",
      " -0.64850842 -0.93134859 -1.1010527   0.36971623  0.03030801 -0.42223627\n",
      "  2.06675729 -0.64850842  0.20001212 -0.3091002   0.70912444  0.93539658\n",
      "  0.93539658  1.50107694  0.70912444  2.46273354 -0.08282806 -1.44046091\n",
      " -1.49702895 -1.1010527  -0.59194038 -0.70507645  0.76569247 -0.25253217\n",
      "  0.82226051 -1.1010527  -0.25253217  0.99196462 -0.19596413 -0.02626002\n",
      " -0.47880431 -0.1393961  -0.76164449 -0.08282806 -1.21418877 -0.64850842\n",
      "  0.99196462 -0.08282806 -0.42223627  0.25658015  0.03030801 -0.93134859\n",
      " -0.70507645 -0.93134859 -0.70507645  0.20001212 -0.93134859 -0.59194038\n",
      " -0.36566824  0.42628426 -0.64850842 -0.70507645  0.93539658  0.99196462\n",
      "  2.63243765 -1.27075681  1.4445089   0.59598837 -0.70507645 -0.1393961\n",
      "  0.6525564  -0.59194038 -0.08282806  0.31314819  0.99196462 -2.00614127\n",
      "  0.36971623  0.70912444 -1.27075681 -0.98791663  0.25658015  0.03030801\n",
      " -0.47880431  0.08687605 -0.70507645  1.10510069 -0.1393961  -0.25253217\n",
      " -0.70507645 -0.53537234 -1.27075681  0.14344408  1.78391712 -0.47880431\n",
      " -0.36566824 -0.08282806  0.03030801 -1.38389288  0.14344408 -0.87478056\n",
      " -0.02626002  0.25658015 -0.70507645 -0.87478056  0.99196462 -2.00614127\n",
      " -1.32732484 -1.49702895 -0.36566824  0.76569247  1.21823676  0.4828523\n",
      " -0.53537234 -0.47880431 -0.42223627 -0.70507645 -0.1393961  -0.02626002\n",
      "  0.20001212  2.12332533 -0.36566824  0.99196462 -0.36566824  3.65066229\n",
      " -0.81821252 -1.32732484  0.59598837 -0.98791663  0.08687605  0.14344408\n",
      " -0.42223627 -0.19596413 -0.87478056 -1.32732484 -0.70507645  0.70912444\n",
      " -0.93134859  0.08687605 -0.36566824 -1.61016502 -0.36566824 -0.08282806\n",
      "  0.14344408 -0.93134859  0.76569247  0.25658015 -1.1010527  -0.81821252\n",
      " -0.47880431  0.31314819 -0.36566824 -0.1393961  -0.42223627 -0.64850842\n",
      " -1.04448466 -0.02626002 -1.27075681  1.21823676 -0.87478056 -1.55359699\n",
      "  2.29302944 -0.64850842 -0.70507645 -1.04448466  1.27480479  0.14344408\n",
      "  0.99196462 -0.64850842 -1.15762074 -1.04448466 -0.70507645 -1.04448466\n",
      "  0.4828523   0.42628426 -0.53537234 -0.76164449 -0.93134859 -0.98791663\n",
      " -0.93134859 -1.77986913  1.27480479 -1.04448466  0.03030801  2.29302944\n",
      " -0.64850842 -0.25253217  0.59598837  0.76569247 -0.70507645 -0.1393961\n",
      " -0.64850842 -0.87478056  1.50107694 -0.59194038  2.01018926 -0.81821252\n",
      "  0.25658015 -0.3091002  -1.55359699 -1.1010527   0.03030801  1.21823676\n",
      "  0.4828523  -0.93134859 -1.27075681 -0.81821252  1.78391712 -1.49702895\n",
      "  1.67078104  0.87882855  0.25658015  1.55764497 -0.87478056 -1.04448466\n",
      "  2.40616551 -1.27075681 -0.25253217 -0.98791663 -0.36566824 -0.47880431\n",
      "  0.76569247 -0.93134859 -0.47880431 -0.53537234 -0.53537234  0.6525564\n",
      " -0.08282806  0.42628426  0.59598837 -0.76164449 -0.36566824 -0.81821252\n",
      " -0.59194038  0.14344408  0.93539658 -0.64850842  0.99196462  0.99196462\n",
      " -0.42223627 -1.55359699 -0.36566824  0.36971623 -1.49702895 -0.59194038\n",
      " -1.21418877  0.31314819  0.25658015 -0.64850842  0.59598837 -0.36566824\n",
      " -1.32732484 -0.3091002  -0.81821252 -0.1393961  -2.00614127 -0.1393961\n",
      "  0.6525564  -0.19596413  0.76569247 -0.02626002 -0.02626002  0.70912444\n",
      " -0.3091002  -1.27075681 -0.47880431  0.25658015 -1.04448466  2.46273354\n",
      " -0.87478056 -0.47880431  0.03030801 -1.55359699  0.03030801 -0.87478056\n",
      "  1.04853265 -1.44046091 -0.02626002  0.93539658 -0.42223627 -1.27075681\n",
      "  2.12332533 -0.3091002  -0.42223627 -0.47880431 -1.04448466 -2.28898145\n",
      "  0.76569247 -1.27075681 -0.81821252 -0.3091002   0.4828523   1.38794087\n",
      "  1.84048515 -0.1393961  -1.27075681 -0.3091002   0.14344408 -0.53537234\n",
      " -1.15762074  0.87882855  0.59598837  0.14344408 -0.93134859 -1.1010527\n",
      "  0.93539658  0.4828523  -1.04448466  0.6525564   0.14344408  0.99196462\n",
      " -0.47880431  0.14344408  0.76569247 -0.47880431 -0.1393961  -1.44046091\n",
      "  0.76569247  1.33137283 -0.87478056  1.16166872  2.12332533 -0.1393961\n",
      " -0.59194038  0.31314819 -0.42223627  3.76379836  1.38794087 -0.36566824\n",
      " -0.08282806  1.50107694 -0.02626002  1.72734908  0.53942033  2.01018926\n",
      " -0.53537234 -0.3091002   0.31314819 -0.36566824 -0.47880431  1.78391712\n",
      "  0.99196462 -0.76164449 -0.53537234  0.53942033 -0.08282806  3.19811801\n",
      " -0.1393961   0.4828523  -0.93134859 -0.02626002  0.36971623 -0.70507645\n",
      " -0.25253217  0.20001212 -0.53537234 -0.98791663 -0.59194038  1.84048515\n",
      "  0.99196462  1.33137283 -0.53537234 -1.1010527   0.20001212  2.29302944\n",
      "  1.16166872 -0.36566824 -0.53537234  0.20001212 -1.15762074  0.08687605\n",
      "  0.82226051  0.87882855 -0.08282806  0.53942033 -1.1010527   1.10510069\n",
      " -0.53537234 -0.59194038 -0.64850842 -0.93134859 -0.08282806  0.03030801\n",
      " -1.04448466 -1.1010527   0.4828523  -0.02626002  0.20001212  0.93539658\n",
      "  0.6525564  -0.53537234  0.20001212  0.53942033 -0.1393961  -0.25253217\n",
      " -0.64850842 -0.1393961   1.50107694  0.14344408  1.50107694 -0.70507645\n",
      "  2.40616551  0.36971623  1.21823676 -0.1393961  -0.87478056 -1.27075681\n",
      " -0.93134859  0.4828523   0.53942033 -0.3091002   0.36971623  0.36971623\n",
      "  0.6525564   0.25658015  0.76569247  3.08498193 -1.32732484 -0.64850842\n",
      "  0.25658015 -0.98791663 -0.3091002   0.70912444  0.70912444  0.87882855\n",
      " -0.53537234  0.42628426 -0.02626002 -0.47880431 -0.53537234 -1.1010527\n",
      " -0.42223627  1.04853265  0.87882855  0.36971623 -0.81821252  0.14344408\n",
      "  1.50107694 -0.19596413 -0.47880431 -0.87478056 -0.3091002  -0.93134859\n",
      "  0.25658015  1.78391712 -1.55359699  1.78391712 -0.53537234  0.4828523\n",
      "  0.36971623 -1.61016502 -1.04448466 -0.81821252  1.78391712 -0.1393961\n",
      "  0.20001212  1.10510069  0.42628426  0.99196462  0.70912444 -1.94957323\n",
      "  0.25658015  1.16166872  0.25658015  2.80214176 -1.77986913  2.57586961\n",
      " -0.3091002  -0.1393961  -0.76164449  0.76569247 -0.36566824  0.14344408\n",
      "  1.67078104  1.78391712  1.33137283 -1.77986913 -0.76164449 -0.76164449\n",
      "  0.6525564   0.42628426  1.04853265  2.29302944 -0.36566824  1.04853265\n",
      " -0.25253217  1.27480479 -0.02626002  0.4828523  -0.76164449  0.08687605\n",
      "  2.97184586 -0.1393961  -0.25253217  0.31314819  0.03030801 -0.59194038\n",
      "  0.08687605  1.50107694 -1.27075681  0.59598837 -0.93134859]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:9] = scaler.fit_transform(X_val.iloc[:, 0:9])\n",
      "/tmp/ipykernel_456912/728613764.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.64313062  1.64313062  1.81381702 -1.34388135  1.64313062 -0.40510616\n",
      "  0.10695304 -0.06373336  1.81381702 -0.49044936  0.53366903  1.72847382\n",
      " -0.31976296  0.96038503  2.15518982 -0.06373336 -0.31976296  0.36298263\n",
      "  0.61901223  0.02160984  0.87504183 -0.40510616 -0.57579256 -0.57579256\n",
      "  0.02160984  1.72847382  0.87504183 -0.40510616 -0.74647896  2.15518982\n",
      " -0.31976296 -0.31976296 -0.91716535  0.36298263 -0.83182216  1.98450342\n",
      " -1.51456775 -1.25853815 -1.77059735 -0.83182216  0.27763944 -1.17319495\n",
      " -0.31976296  0.19229624  0.44832583 -0.91716535 -0.49044936 -0.66113576\n",
      " -1.68525415  0.70435543 -0.49044936  0.61901223  0.02160984 -0.40510616\n",
      " -0.91716535  0.19229624  0.36298263  0.53366903  0.53366903 -0.14907656\n",
      "  0.70435543 -1.08785175  0.53366903  0.53366903  0.36298263  0.53366903\n",
      "  0.96038503  0.61901223  1.13107143  2.32587622  0.70435543 -1.25853815\n",
      " -0.91716535 -0.91716535  0.02160984  0.87504183 -0.06373336  0.53366903\n",
      "  0.70435543 -0.66113576  0.53366903  0.36298263 -0.83182216  0.02160984\n",
      " -0.74647896  0.19229624 -0.40510616  0.78969863 -0.66113576  0.02160984\n",
      "  3.52068101  0.96038503  0.44832583  0.19229624  0.78969863 -0.57579256\n",
      " -1.17319495 -0.49044936  0.10695304 -0.40510616 -0.83182216 -0.49044936\n",
      "  0.10695304  0.44832583 -0.23441976 -0.31976296  0.78969863  2.32587622\n",
      "  0.61901223 -0.74647896 -0.23441976  0.96038503 -1.17319495 -0.74647896\n",
      " -1.17319495 -1.51456775 -0.40510616  0.44832583  0.96038503 -0.66113576\n",
      "  0.10695304 -1.59991095 -0.31976296 -1.59991095 -0.23441976 -0.31976296\n",
      " -1.08785175  0.44832583 -0.40510616  0.10695304  0.78969863 -0.83182216\n",
      " -0.14907656 -0.06373336 -1.59991095 -0.40510616  1.81381702 -0.74647896\n",
      "  0.19229624  0.70435543  0.02160984 -1.00250855 -0.31976296 -0.14907656\n",
      "  0.70435543 -0.40510616 -0.74647896 -0.14907656  1.38710103 -2.02662694\n",
      " -0.14907656 -0.06373336 -0.49044936  1.81381702  0.19229624 -1.17319495\n",
      "  0.27763944  0.96038503 -0.31976296 -1.25853815 -1.42922455  0.19229624\n",
      "  0.96038503  0.96038503  0.53366903  0.19229624  0.70435543  2.58190582\n",
      " -0.40510616 -1.17319495  0.27763944 -1.00250855  0.53366903  0.53366903\n",
      " -1.08785175  0.78969863 -0.06373336 -1.25853815 -1.00250855  0.96038503\n",
      " -1.25853815  0.19229624 -0.31976296 -1.68525415 -1.25853815 -0.57579256\n",
      " -0.14907656  0.27763944  0.61901223 -0.66113576 -2.53868614  0.10695304\n",
      " -0.49044936  0.27763944 -0.49044936  0.10695304 -0.49044936 -0.23441976\n",
      " -0.57579256 -1.17319495 -0.23441976  1.64313062 -0.66113576 -1.42922455\n",
      "  3.8620538  -0.91716535 -1.25853815 -0.31976296 -0.66113576  0.36298263\n",
      "  0.87504183 -0.49044936 -1.85594055 -0.31976296 -0.23441976 -0.40510616\n",
      "  0.87504183  0.61901223 -0.31976296 -0.66113576 -0.14907656  0.02160984\n",
      " -2.19731334 -1.34388135 -0.66113576 -0.83182216 -0.49044936  2.49656262\n",
      " -1.59991095  0.36298263  0.10695304  0.78969863 -0.40510616 -0.14907656\n",
      " -0.31976296 -0.49044936  0.44832583 -0.31976296 -0.74647896 -0.57579256\n",
      "  0.02160984 -0.14907656  0.70435543 -0.31976296  1.21641463 -0.14907656\n",
      "  0.19229624  1.04572823 -0.40510616 -0.83182216  1.30175783 -0.49044936\n",
      "  1.55778742  1.72847382  0.78969863 -0.66113576 -0.06373336 -0.66113576\n",
      "  1.21641463 -0.57579256  0.19229624  0.10695304  0.70435543 -2.19731334\n",
      " -0.31976296 -0.49044936 -0.06373336  0.19229624 -0.66113576 -0.31976296\n",
      " -0.74647896 -0.57579256 -0.14907656 -1.94128375  0.70435543 -0.06373336\n",
      " -1.94128375  0.96038503  1.81381702 -0.40510616 -0.40510616 -0.31976296\n",
      " -0.06373336 -1.08785175 -0.49044936  1.89916022 -1.08785175 -0.66113576\n",
      " -0.14907656  0.96038503  0.27763944 -1.42922455  0.70435543 -0.57579256\n",
      " -0.66113576  1.04572823  0.02160984 -0.40510616 -1.85594055 -0.23441976\n",
      "  0.53366903  0.36298263  0.87504183 -1.25853815 -0.23441976  1.72847382\n",
      " -0.06373336 -0.74647896  0.36298263 -0.57579256 -2.28265654  4.0327402\n",
      " -1.08785175 -0.14907656 -0.31976296 -0.66113576 -0.23441976 -0.23441976\n",
      "  0.53366903 -2.28265654  0.02160984  2.49656262  0.27763944 -1.85594055\n",
      "  0.44832583 -0.23441976  0.19229624  0.44832583 -0.57579256 -1.00250855\n",
      " -0.06373336 -0.40510616  0.02160984  0.02160984  0.36298263 -0.40510616\n",
      "  1.55778742  0.27763944 -0.66113576 -1.25853815 -0.31976296 -0.66113576\n",
      " -0.66113576  1.55778742  1.13107143 -0.57579256 -0.49044936 -1.42922455\n",
      " -1.17319495 -1.42922455 -0.31976296  1.38710103 -0.06373336  0.10695304\n",
      "  0.02160984  0.78969863  1.13107143 -1.00250855 -0.91716535 -1.94128375\n",
      "  0.44832583 -0.49044936 -0.23441976  2.41121942  1.38710103  0.27763944\n",
      " -0.06373336  0.36298263  0.61901223  1.64313062  1.30175783 -1.08785175\n",
      "  0.27763944  0.87504183  0.02160984  2.06984662 -0.31976296  1.55778742\n",
      " -1.34388135  0.19229624 -0.06373336  0.78969863  0.27763944 -1.17319495\n",
      "  0.19229624 -0.31976296 -0.66113576  0.27763944 -1.42922455  3.09396501\n",
      "  0.78969863 -0.91716535  0.44832583 -1.08785175  0.10695304  0.19229624\n",
      " -1.00250855 -0.14907656 -0.31976296  1.04572823 -0.06373336  1.38710103\n",
      "  0.10695304 -1.08785175 -1.77059735  1.30175783  0.02160984  0.19229624\n",
      "  1.89916022  0.87504183 -1.59991095  0.02160984 -0.74647896  0.10695304\n",
      " -0.14907656 -0.40510616  1.21641463  0.10695304 -0.66113576  0.19229624\n",
      "  0.19229624 -0.40510616 -0.06373336  0.10695304  0.78969863 -0.40510616\n",
      "  0.36298263 -0.23441976 -0.57579256  1.30175783 -1.25853815  1.30175783\n",
      "  0.78969863 -0.83182216 -0.66113576  1.81381702 -1.08785175 -0.91716535\n",
      " -2.53868614  0.53366903  1.04572823 -0.31976296 -0.40510616 -0.40510616\n",
      "  1.81381702 -0.06373336  1.47244423  0.53366903 -0.49044936 -1.77059735\n",
      "  0.19229624 -0.23441976  1.04572823 -0.14907656 -0.23441976  1.04572823\n",
      " -0.31976296  0.87504183 -0.66113576  1.81381702 -0.66113576  0.27763944\n",
      "  0.27763944 -1.34388135  0.36298263  0.61901223 -1.25853815  1.47244423\n",
      " -0.40510616  0.44832583 -0.83182216 -1.08785175 -1.59991095 -0.91716535\n",
      "  0.10695304  1.13107143  0.61901223  0.19229624 -1.17319495 -1.17319495\n",
      "  0.27763944  0.10695304 -0.83182216 -0.74647896  0.44832583 -0.31976296\n",
      " -0.23441976  3.52068101 -1.68525415  2.24053302 -0.74647896  0.36298263\n",
      "  0.53366903 -1.51456775 -1.25853815  0.36298263  1.81381702 -0.31976296\n",
      " -1.08785175  0.70435543  1.30175783  0.78969863  0.27763944 -1.59991095\n",
      "  0.36298263  1.30175783  0.61901223 -0.40510616 -0.91716535  0.02160984\n",
      " -0.66113576  0.44832583 -0.14907656  0.19229624 -0.31976296 -0.40510616\n",
      "  1.64313062  1.55778742 -0.40510616 -1.25853815  0.19229624 -1.08785175\n",
      "  0.87504183  1.04572823  0.78969863  1.55778742  0.19229624  0.70435543\n",
      " -0.23441976  1.55778742  0.70435543 -0.66113576 -1.08785175  0.53366903\n",
      "  3.00862181 -1.08785175  0.61901223  1.38710103  0.02160984 -0.31976296\n",
      "  0.27763944  1.98450342 -1.00250855  0.27763944 -0.57579256]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:9] = scaler.fit_transform(X_val.iloc[:, 0:9])\n",
      "/tmp/ipykernel_456912/728613764.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 2.63083562e-04 -1.07403864e-01  3.23263927e-01 ... -2.04540893e+00\n",
      "  4.30930875e-01  1.07930031e-01]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:9] = scaler.fit_transform(X_val.iloc[:, 0:9])\n",
      "/tmp/ipykernel_456912/728613764.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.493484   -0.493484   -2.21991869 ... -0.493484   -0.493484\n",
      " -0.493484  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:9] = scaler.fit_transform(X_val.iloc[:, 0:9])\n",
      "/tmp/ipykernel_456912/728613764.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.73052642 -2.39087614 -0.5180346  ... -0.5180346   0.10624591\n",
      " -0.5180346 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:9] = scaler.fit_transform(X_val.iloc[:, 0:9])\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Validation Set 2':                  Mean  CI Lower  CI Upper\n",
       " AUC          0.725779  0.672009  0.775053\n",
       " Accuracy     0.874119  0.858277  0.888821\n",
       " Sensitivity  0.218851  0.129253  0.320761\n",
       " Specificity  0.900785  0.886132  0.915082\n",
       " PPV          0.082311  0.044188  0.123436\n",
       " NPV          0.965915  0.956224  0.974675\n",
       " LR+          2.218923  1.264509  3.342768\n",
       " LR-          0.867258  0.755201  0.970940\n",
       " DOR          2.610352  1.300224  4.391295\n",
       " F1           0.119183  0.065421  0.175007\n",
       " F2           0.163589  0.093333  0.235565\n",
       " Brier Score  0.091743  0.082648  0.100733,\n",
       " 'Validation Set 3':                  Mean  CI Lower  CI Upper\n",
       " AUC          0.727498  0.685123  0.769549\n",
       " Accuracy     0.652182  0.612844  0.688119\n",
       " Sensitivity  0.232102  0.176160  0.291084\n",
       " Specificity  0.919002  0.890241  0.948496\n",
       " PPV          0.645437  0.538433  0.753256\n",
       " NPV          0.653244  0.610870  0.694470\n",
       " LR+          2.977613  1.866768  4.685881\n",
       " LR-          0.835819  0.768288  0.904467\n",
       " DOR          3.599056  2.059877  5.992705\n",
       " F1           0.340684  0.268007  0.409582\n",
       " F2           0.265970  0.204289  0.328813\n",
       " Brier Score  0.253222  0.225870  0.280816,\n",
       " 'Validation Set 4':                  Mean  CI Lower   CI Upper\n",
       " AUC          0.735697  0.658085   0.805980\n",
       " Accuracy     0.589478  0.516854   0.657303\n",
       " Sensitivity  0.226848  0.140995   0.317660\n",
       " Specificity  0.944991  0.896522   0.988636\n",
       " PPV          0.801227  0.640000   0.944518\n",
       " NPV          0.554961  0.477412   0.629383\n",
       " LR+               inf  1.898742  17.863757\n",
       " LR-          0.818652  0.717198   0.915663\n",
       " DOR               inf  2.094721  21.401190\n",
       " F1           0.351450  0.234017   0.464007\n",
       " F2           0.264243  0.166667   0.362922\n",
       " Brier Score  0.316710  0.262318   0.373308}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on validation sets\n",
    "validation_sets = [\n",
    "    pd.read_csv('~/data/BAH_PRS/version10/ml_dat/pato.csv',sep=',',header=0),\n",
    "    pd.read_csv('~/data/BAH_PRS/version10/ml_dat/monash.csv',sep=',',header=0),\n",
    "    pd.read_csv('~/data/BAH_PRS/version10/ml_dat/ljubljana.csv',sep=',',header=0)\n",
    "]\n",
    "\n",
    "def evaluate_single_validation_set(df, model, scaler):\n",
    "    X_val = df[set2]\n",
    "    y_val = df['IHA']\n",
    "    X_val.iloc[:, 0:9] = scaler.fit_transform(X_val.iloc[:, 0:9])  \n",
    "    \n",
    "    y_prob = model.predict_proba(X_val)[:, 1]\n",
    "    return bootstrap_metrics(y_val, y_prob)\n",
    "\n",
    "def evaluate_on_validation_sets(model, validation_sets, scaler):\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {\n",
    "            f'Validation Set {i+2}': executor.submit(evaluate_single_validation_set, df, model, scaler)\n",
    "            for i, df in enumerate(validation_sets)\n",
    "        }\n",
    "        for key, future in futures.items():\n",
    "            results[key] = future.result()\n",
    "    return results\n",
    "\n",
    "# Evaluate on validation sets\n",
    "results_df2 = evaluate_on_validation_sets(model, validation_sets, scaler)\n",
    "results_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61790c6c-2cbf-456c-964e-ab4023208912",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df1.to_csv('/home/luo_wenjin/data/BAH_PRS/version10/ml_dat/conpass_training_boot_model2.csv', index=True)\n",
    "for key, value in results_df2.items():\n",
    "    value.to_csv(f'/home/luo_wenjin/data/BAH_PRS/version10/ml_dat/{key}_boot_model2.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecaf35c1-432e-4b94-87d8-4f38daea6c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_456912/2810011555.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.92946149  1.2437939   1.15808545 ...  0.90096011  0.12958407\n",
      " -0.81320887]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train_scaled.iloc[:,0:8] = scaler.fit_transform(X_train_scaled.iloc[:,0:8])\n",
      "/tmp/ipykernel_456912/2810011555.py:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.15604266  0.47241786 -0.12754128  0.72954321 -1.58458491  1.92946149\n",
      " -0.04183283  0.55812631  1.67233615  0.04387562 -0.47037507 -0.12754128\n",
      "  0.38670942 -0.21324973 -0.89891732 -2.95592009  1.2437939  -1.49887646\n",
      "  1.15808545  1.07237701  1.32950235  0.72954321  0.12958407 -0.64179197\n",
      " -1.41316801 -0.55608352  1.2437939  -0.55608352  0.98666856 -0.29895817\n",
      "  0.38670942 -1.58458491  0.38670942 -1.49887646 -2.35596094 -1.49887646\n",
      " -0.89891732 -0.72750042  1.84375304 -2.2702525  -0.21324973  1.50091925\n",
      " -0.72750042  3.04367133  0.12958407  0.81525166  1.4152108  -0.38466662\n",
      "  0.72954321 -1.15604266  0.12958407 -1.41316801  1.07237701 -0.21324973\n",
      "  1.4152108  -0.89891732 -0.29895817  1.5866277   1.15808545 -1.07033421\n",
      " -1.07033421  0.04387562 -0.81320887 -2.01312715  1.32950235  1.07237701\n",
      "  1.32950235  1.32950235 -0.72750042 -0.98462576  0.72954321  1.67233615\n",
      "  1.32950235 -0.98462576  0.55812631  1.67233615 -0.98462576 -0.38466662\n",
      "  0.90096011  0.98666856 -0.04183283  0.21529252 -0.04183283  1.67233615\n",
      "  0.12958407  0.38670942 -0.47037507 -0.55608352  0.90096011 -1.24175111\n",
      "  0.47241786 -0.04183283  0.30100097  1.07237701  1.2437939   0.30100097\n",
      "  0.04387562 -0.64179197 -0.55608352  0.72954321 -0.21324973 -1.7560018\n",
      "  0.64383476 -0.72750042  1.15808545 -0.64179197  0.47241786 -0.55608352\n",
      " -0.47037507 -1.7560018  -0.04183283 -0.81320887 -1.24175111  1.32950235\n",
      "  1.4152108   1.5866277   0.64383476 -1.67029335  1.32950235 -0.55608352\n",
      "  1.7580446   2.10087839  1.4152108  -1.41316801 -1.49887646 -1.41316801\n",
      "  0.30100097 -1.49887646  0.90096011 -0.29895817 -0.04183283  1.84375304\n",
      "  0.38670942  0.12958407  0.04387562  1.2437939   1.4152108   0.47241786\n",
      " -0.04183283 -1.49887646  0.21529252  0.81525166  0.04387562 -1.7560018\n",
      "  0.12958407  0.90096011 -0.98462576  1.7580446  -0.55608352 -0.21324973\n",
      "  0.04387562 -1.67029335  0.47241786  0.55812631  1.50091925  1.4152108\n",
      " -1.58458491 -1.9274187  -0.21324973 -1.58458491  1.7580446  -2.18454405\n",
      "  0.21529252  0.04387562  0.47241786 -0.12754128 -0.04183283  0.38670942\n",
      " -2.2702525   1.2437939  -0.89891732  0.12958407  1.15808545 -1.32745956\n",
      "  1.92946149  1.50091925 -1.67029335 -1.32745956 -0.04183283  0.30100097\n",
      "  1.07237701 -1.15604266  1.50091925  0.38670942  1.07237701  0.12958407\n",
      " -1.7560018   0.30100097  0.55812631 -0.64179197  3.38650512 -0.12754128\n",
      " -1.15604266 -0.81320887  1.07237701  1.15808545  0.55812631 -2.01312715\n",
      " -1.49887646 -1.58458491 -0.21324973  1.2437939  -0.12754128 -0.12754128\n",
      " -0.29895817  0.55812631 -1.32745956  1.5866277  -0.21324973  0.64383476\n",
      " -0.64179197  0.30100097 -0.04183283 -1.49887646  0.38670942 -0.12754128\n",
      " -0.38466662  0.30100097  1.84375304 -0.55608352 -0.89891732  0.55812631\n",
      "  0.04387562 -2.2702525   1.4152108  -2.35596094  0.98666856  0.38670942\n",
      "  0.55812631  0.30100097 -1.49887646 -1.15604266 -0.21324973 -0.29895817\n",
      "  1.07237701  1.32950235 -1.32745956  0.04387562  0.12958407 -1.7560018\n",
      " -1.07033421 -1.49887646  1.32950235 -0.29895817  0.72954321 -2.44166939\n",
      " -0.55608352 -0.04183283  0.21529252  2.10087839 -1.07033421 -1.58458491\n",
      " -0.47037507 -0.04183283 -2.18454405 -0.98462576  0.04387562 -0.21324973\n",
      "  1.50091925  1.2437939   0.30100097  0.38670942 -0.29895817 -0.38466662\n",
      "  2.01516994  0.72954321 -1.9274187  -0.89891732  2.27229529 -0.38466662\n",
      " -0.47037507  1.15808545 -1.24175111 -2.18454405  0.98666856 -0.29895817\n",
      "  0.55812631 -1.07033421  0.38670942  0.47241786  0.64383476  1.07237701\n",
      " -1.32745956 -0.21324973  0.64383476 -1.41316801  0.30100097  0.72954321\n",
      " -0.89891732  0.47241786  0.98666856  1.07237701 -0.98462576 -2.18454405\n",
      "  0.12958407  0.90096011 -0.98462576 -1.49887646  0.12958407 -2.44166939\n",
      "  0.04387562 -0.12754128 -0.47037507 -0.72750042  0.81525166  0.47241786\n",
      " -0.04183283  0.90096011  1.15808545 -1.67029335 -0.64179197  1.15808545\n",
      "  0.47241786 -1.15604266  1.67233615 -0.29895817 -1.07033421 -1.84171025\n",
      " -0.89891732  1.50091925 -1.58458491 -1.32745956  0.72954321 -0.12754128\n",
      " -1.32745956 -0.12754128  1.15808545 -0.47037507  0.98666856  0.64383476\n",
      " -1.49887646  1.2437939  -1.67029335  0.30100097 -0.55608352 -0.29895817\n",
      " -1.49887646  0.72954321  0.72954321  1.2437939  -0.04183283  0.72954321\n",
      " -0.12754128  0.21529252 -0.38466662  1.07237701  1.84375304  1.15808545\n",
      "  0.04387562  1.84375304  1.4152108  -0.81320887 -0.38466662 -1.32745956\n",
      "  0.64383476 -2.18454405 -0.04183283 -0.29895817 -1.41316801 -0.89891732\n",
      "  0.21529252  1.84375304 -1.41316801 -0.72750042 -1.07033421 -1.58458491\n",
      " -0.55608352 -0.55608352 -0.21324973  0.30100097  0.55812631  0.04387562\n",
      "  0.21529252 -0.12754128  1.92946149  0.72954321  0.90096011 -0.12754128\n",
      "  0.30100097 -0.04183283 -0.04183283 -0.12754128 -0.89891732 -0.72750042\n",
      " -0.21324973 -0.21324973 -1.41316801  0.12958407 -0.29895817  3.12937978\n",
      "  0.21529252 -1.24175111 -1.24175111 -0.47037507 -2.0988356  -0.98462576\n",
      "  1.15808545 -1.24175111  0.98666856 -0.55608352 -1.58458491 -1.7560018\n",
      " -0.12754128  1.7580446   0.04387562  2.61512908  1.4152108   0.81525166\n",
      "  1.2437939   1.67233615  0.98666856 -0.12754128  0.90096011 -2.87021164\n",
      " -1.07033421  1.67233615 -0.04183283  1.07237701 -0.29895817 -2.0988356\n",
      " -0.72750042 -1.15604266 -1.15604266  0.47241786 -0.12754128  0.55812631\n",
      " -0.38466662 -0.81320887  2.10087839 -0.29895817 -0.89891732  1.32950235\n",
      "  1.67233615 -0.29895817  0.12958407  0.47241786 -0.38466662 -0.72750042\n",
      "  1.15808545 -2.01312715 -1.24175111  2.10087839 -1.58458491 -0.64179197\n",
      "  0.47241786 -0.29895817  0.04387562 -2.2702525  -1.32745956  1.07237701\n",
      "  2.01516994 -1.41316801 -0.21324973 -0.55608352  1.2437939  -0.38466662\n",
      " -0.47037507  0.12958407 -0.12754128 -0.04183283 -0.12754128  1.84375304\n",
      " -0.21324973  0.04387562  1.67233615 -0.55608352 -0.72750042 -0.55608352\n",
      "  0.98666856 -0.04183283  0.47241786 -0.12754128 -2.01312715  0.98666856\n",
      "  0.38670942  0.55812631 -0.98462576 -3.04162854  1.67233615 -0.89891732\n",
      "  0.04387562 -0.29895817  0.38670942 -0.81320887  0.21529252  0.72954321\n",
      "  0.04387562  0.55812631 -1.07033421 -0.21324973  0.38670942  0.38670942\n",
      "  0.64383476 -1.07033421 -0.21324973 -1.15604266  0.55812631 -0.55608352\n",
      " -1.32745956 -1.49887646  0.12958407 -0.38466662  0.38670942  0.38670942]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test_scaled.iloc[:,0:8] = scaler.transform(X_test_scaled.iloc[:,0:8])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TabPFNClassifier(balance_probabilities=True, device=&#x27;cpu&#x27;, n_estimators=32,\n",
       "                 random_state=42, softmax_temperature=0.6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TabPFNClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TabPFNClassifier(balance_probabilities=True, device=&#x27;cpu&#x27;, n_estimators=32,\n",
       "                 random_state=42, softmax_temperature=0.6)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TabPFNClassifier(balance_probabilities=True, device='cpu', n_estimators=32,\n",
       "                 random_state=42, softmax_temperature=0.6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>CI Lower</th>\n",
       "      <th>CI Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.697751</td>\n",
       "      <td>0.633860</td>\n",
       "      <td>0.754083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.817431</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>0.845238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.174067</td>\n",
       "      <td>0.097819</td>\n",
       "      <td>0.255821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.949912</td>\n",
       "      <td>0.928073</td>\n",
       "      <td>0.969938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>0.417836</td>\n",
       "      <td>0.256250</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>0.848139</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.876575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR+</th>\n",
       "      <td>3.667345</td>\n",
       "      <td>1.766227</td>\n",
       "      <td>6.574180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR-</th>\n",
       "      <td>0.869611</td>\n",
       "      <td>0.782127</td>\n",
       "      <td>0.953385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOR</th>\n",
       "      <td>4.289567</td>\n",
       "      <td>1.851390</td>\n",
       "      <td>8.508141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.244246</td>\n",
       "      <td>0.143971</td>\n",
       "      <td>0.340451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>0.196562</td>\n",
       "      <td>0.112219</td>\n",
       "      <td>0.283784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brier Score</th>\n",
       "      <td>0.145465</td>\n",
       "      <td>0.123722</td>\n",
       "      <td>0.171733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Mean  CI Lower  CI Upper\n",
       "AUC          0.697751  0.633860  0.754083\n",
       "Accuracy     0.817431  0.783730  0.845238\n",
       "Sensitivity  0.174067  0.097819  0.255821\n",
       "Specificity  0.949912  0.928073  0.969938\n",
       "PPV          0.417836  0.256250  0.600000\n",
       "NPV          0.848139  0.815445  0.876575\n",
       "LR+          3.667345  1.766227  6.574180\n",
       "LR-          0.869611  0.782127  0.953385\n",
       "DOR          4.289567  1.851390  8.508141\n",
       "F1           0.244246  0.143971  0.340451\n",
       "F2           0.196562  0.112219  0.283784\n",
       "Brier Score  0.145465  0.123722  0.171733"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df1[set3]\n",
    "y = df1['IHA']\n",
    "\n",
    "smotenc = SMOTENC(categorical_features=[8,9], \n",
    "                  random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)\n",
    "X_train_resampled, y_train_resampled = smotenc.fit_resample(X_train, y_train)\n",
    "X_train_scaled = X_train_resampled\n",
    "X_test_scaled = X_test\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled.iloc[:,0:8] = scaler.fit_transform(X_train_scaled.iloc[:,0:8])\n",
    "X_test_scaled.iloc[:,0:8] = scaler.transform(X_test_scaled.iloc[:,0:8])\n",
    "\n",
    "model = TabPFNClassifier(n_estimators=32, device='cpu', random_state=42, softmax_temperature=0.6, balance_probabilities=True)\n",
    "model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "results_df1 = bootstrap_metrics(y_test, y_prob)\n",
    "results_df1\n",
    "# Save probabilities\n",
    "pd.DataFrame(y_prob, columns=['Probability']).to_csv('/home/luo_wenjin/data/BAH_PRS/version10/ml_dat/prob_model3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8354779b-b5bd-474b-8efc-82518803d6bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_456912/2476877814.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.98698266 -0.80089916 -1.17729534  0.61058649  0.89288362 -1.08319629\n",
      "  0.70468553 -0.51860203  0.32828936 -0.42450299 -0.98909725  0.89288362\n",
      " -0.04810681 -0.42450299 -0.14220586 -0.33040394 -1.17729534 -1.17729534\n",
      " -2.30648386  0.51648745 -1.55369151 -0.80089916  0.23419032  0.98698266\n",
      "  1.08108171 -1.45959247  1.17518075 -2.11828577 -0.33040394  0.70468553\n",
      "  0.51648745 -2.4005829  -0.89499821 -1.08319629 -0.04810681 -0.14220586\n",
      "  0.23419032  0.61058649  0.70468553  0.14009127 -1.08319629  0.70468553\n",
      " -0.70680012 -0.14220586 -0.33040394  0.14009127  0.61058649 -0.33040394\n",
      " -0.51860203 -1.27139438  1.17518075 -0.42450299  0.51648745  0.04599223\n",
      " -0.42450299  1.36337884  0.32828936 -0.14220586  0.32828936  0.32828936\n",
      "  1.17518075 -1.08319629  1.17518075 -0.51860203  0.79878458  0.98698266\n",
      " -0.70680012  0.4223884   1.08108171  0.14009127 -0.51860203 -0.14220586\n",
      "  1.08108171  0.23419032 -0.42450299 -0.98909725 -1.45959247 -0.04810681\n",
      "  0.14009127  0.04599223  0.14009127 -0.33040394 -0.70680012  0.04599223\n",
      " -0.70680012 -0.14220586  0.70468553  1.26927979 -1.27139438 -1.36549342\n",
      " -0.14220586  0.89288362 -0.33040394 -1.83598864  1.26927979  0.98698266\n",
      " -0.42450299  0.32828936 -0.33040394 -1.17729534 -0.2363049   1.45747788\n",
      "  1.17518075  0.4223884   0.4223884   0.79878458 -0.04810681 -0.2363049\n",
      "  0.32828936  0.98698266  0.98698266 -3.52977142 -0.33040394 -0.2363049\n",
      "  0.4223884   0.98698266  1.73977501 -1.08319629  0.51648745  0.14009127\n",
      " -0.33040394  0.61058649  0.61058649 -3.24747429  1.45747788  0.32828936\n",
      " -0.14220586 -0.70680012 -0.70680012 -0.42450299 -2.49468194  1.17518075\n",
      "  0.98698266 -1.64779055  1.26927979  0.61058649 -0.33040394 -0.98909725\n",
      "  1.26927979 -0.70680012 -0.51860203  1.36337884  0.79878458  0.98698266\n",
      "  2.02207214  0.04599223  0.79878458  0.61058649  1.45747788  0.89288362\n",
      " -1.36549342  1.08108171  0.70468553 -1.08319629  1.17518075 -1.27139438\n",
      "  0.14009127 -1.55369151  0.70468553  0.79878458  0.98698266  1.08108171\n",
      "  0.98698266 -1.7418896   0.4223884   1.45747788  0.89288362 -1.64779055\n",
      " -1.55369151  0.51648745 -0.51860203 -0.42450299  1.64567597 -1.27139438\n",
      "  0.04599223  1.08108171 -0.51860203  1.17518075]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:8] = scaler.fit_transform(X_val.iloc[:, 0:8])\n",
      "/tmp/ipykernel_456912/2476877814.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.58078406  0.08678041  0.26231351  0.17454696 -0.615352    2.28094419\n",
      "  1.13997902 -0.615352   -1.14195131 -1.22971786  1.40327868  2.28094419\n",
      "  0.35008006 -0.52758545  0.08678041  0.52561317  0.78891282  0.43784661\n",
      " -0.08875269  0.52561317 -0.52758545 -1.58078406  1.40327868 -0.17651924\n",
      "  1.49104523 -0.615352   -0.70311855  0.70114627  0.52561317  0.52561317\n",
      "  1.57881178  0.26231351 -1.05418476  2.28094419  0.43784661  0.52561317\n",
      "  0.52561317 -1.14195131  0.43784661 -1.75631716  1.40327868  0.08678041\n",
      "  0.08678041  0.26231351  2.28094419 -1.58078406  0.08678041  0.08678041\n",
      "  0.70114627  1.57881178 -0.52758545  1.40327868  0.61337972  0.08678041\n",
      "  0.70114627  0.35008006  0.35008006  0.52561317 -0.52758545  0.08678041\n",
      "  0.08678041 -0.7908851   0.52561317  0.08678041  1.57881178  0.78891282\n",
      "  0.26231351  0.52561317 -0.35205235  0.87667937 -0.17651924 -1.58078406\n",
      "  0.08678041 -1.58078406  1.49104523 -0.35205235 -0.52758545  0.78891282\n",
      " -0.7908851   0.17454696 -0.615352    1.57881178  0.87667937  0.26231351\n",
      " -1.84408372 -1.58078406  0.78891282  0.08678041  0.26231351  0.43784661\n",
      "  0.08678041 -0.87865165 -0.26428579 -1.58078406  0.08678041  2.28094419\n",
      " -1.75631716 -0.52758545 -0.4398189  -1.75631716 -2.89728233 -0.52758545\n",
      " -0.7908851  -1.66855061  1.57881178  0.26231351 -0.08875269  0.08678041\n",
      " -1.14195131 -1.14195131 -0.35205235 -1.75631716  0.43784661  0.26231351\n",
      "  0.87667937 -1.84408372 -0.08875269 -0.52758545 -1.84408372  2.28094419\n",
      " -0.615352   -2.89728233  0.08678041  0.43784661  0.26231351 -1.84408372\n",
      "  0.35008006  0.17454696 -0.52758545  0.43784661  0.17454696  0.08678041\n",
      "  1.57881178  1.40327868 -0.35205235  0.61337972  0.35008006  0.43784661\n",
      " -0.9664182   0.70114627 -0.87865165  0.08678041  0.87667937 -0.615352\n",
      " -0.4398189   0.70114627  0.08678041 -0.35205235  0.08678041  0.08678041\n",
      "  0.08678041  0.43784661 -0.7908851  -0.70311855  0.43784661  0.87667937\n",
      "  0.08678041 -1.58078406 -0.52758545 -1.75631716 -0.87865165 -0.7908851\n",
      "  0.70114627  0.17454696  1.49104523  1.57881178  0.35008006 -1.22971786\n",
      "  0.78891282  0.43784661 -0.52758545  0.08678041  0.26231351 -1.14195131\n",
      " -0.52758545  0.26231351  0.35008006 -0.9664182 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:8] = scaler.fit_transform(X_val.iloc[:, 0:8])\n",
      "/tmp/ipykernel_456912/2476877814.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.71503218 -0.85828245  1.52881562 -1.23804805  0.82353664 -0.31576016\n",
      " -0.04449902  1.20330224  2.55960796 -1.78057034  0.76928441  1.09479779\n",
      " -1.02103914  0.00975321  0.71503218 -0.26150793 -1.67206588  0.9320411\n",
      " -0.15300348 -0.42426462 -0.37001239  0.87778887 -0.20725571  2.01708567\n",
      "  0.28101435 -0.26150793 -0.42426462 -1.07529137  2.23409459 -0.09875125\n",
      "  0.22676212 -0.26150793  0.00975321 -0.85828245  1.85432899  1.36605893\n",
      "  1.04054556  1.80007676  3.15638248 -0.20725571 -0.42426462  0.9320411\n",
      "  0.60652773  0.33526658  2.93937356 -0.37001239  0.71503218  0.06400544\n",
      " -0.69552576  0.60652773  1.14905001 -0.64127354  0.1725099  -0.09875125\n",
      "  0.71503218 -0.37001239 -2.05183148 -1.29230028  0.5522755   0.38951881\n",
      "  2.4511035   0.00975321 -1.67206588  1.14905001 -0.09875125 -0.37001239\n",
      "  0.9320411   0.71503218  0.60652773  0.00975321  0.76928441  0.60652773\n",
      " -2.05183148 -0.80403022  1.14905001  0.11825767 -0.04449902  2.50535573\n",
      " -0.69552576  1.6915723   0.11825767 -1.07529137  0.49802327 -0.42426462\n",
      " -1.34655251 -0.26150793  0.60652773  1.3118067  -0.58702131  0.87778887\n",
      "  0.28101435 -0.80403022  0.00975321 -0.64127354  0.00975321  0.00975321\n",
      " -0.91253468 -0.53276908  0.76928441  0.28101435 -0.42426462  1.58306784\n",
      " -0.42426462 -0.85828245  0.00975321 -0.80403022 -0.80403022  1.36605893\n",
      " -0.20725571 -0.26150793  1.25755447 -1.56356142 -0.42426462  0.00975321\n",
      " -1.07529137  0.1725099   1.63732007 -1.83482257  0.11825767  0.11825767\n",
      " -0.37001239 -1.02103914 -0.04449902 -1.29230028 -0.58702131 -0.91253468\n",
      " -1.18379582  0.33526658 -0.37001239 -0.91253468 -1.12954359 -0.15300348\n",
      " -0.85828245 -0.64127354 -1.07529137 -0.91253468 -0.53276908  0.33526658\n",
      "  0.5522755  -0.26150793 -1.29230028  0.66077995  0.00975321  0.76928441\n",
      "  1.09479779 -1.83482257  0.38951881 -1.23804805  1.6915723  -0.26150793\n",
      "  0.44377104  0.11825767 -1.67206588 -0.58702131 -0.04449902 -1.07529137\n",
      " -1.12954359 -1.78057034 -0.31576016 -1.07529137  0.49802327  0.66077995\n",
      " -1.02103914 -1.23804805  0.82353664  0.06400544  0.49802327 -1.29230028\n",
      " -1.23804805 -0.91253468  0.00975321 -0.69552576  0.5522755   0.5522755\n",
      "  1.09479779 -0.26150793  0.28101435  0.11825767]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:8] = scaler.fit_transform(X_val.iloc[:, 0:8])\n",
      "/tmp/ipykernel_456912/2476877814.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.49558123 -0.60076195  1.92926077 -0.09475741  0.24257896 -0.51642786\n",
      "  0.83291759  0.32691305  1.25458805 -1.0224324  -0.60076195  0.66424941\n",
      " -0.60076195 -0.01042331  1.00158577  0.49558123  0.7485835   0.49558123\n",
      "  1.42325623  0.24257896 -0.01042331  0.49558123  0.32691305  0.15824487\n",
      " -1.27543468  1.08591987 -0.51642786 -0.60076195  1.6762585  -0.43209377\n",
      "  0.24257896 -0.60076195  0.66424941  1.42325623  1.00158577  0.41124714\n",
      " -0.01042331  0.24257896  1.25458805 -0.93809831  0.49558123 -0.85376422\n",
      "  1.50759032  0.91725168  3.78461077 -0.68509604 -0.43209377  0.91725168\n",
      " -0.43209377  0.24257896 -1.10676649 -0.26342559  0.91725168 -0.43209377\n",
      "  2.51959941  0.07391078 -2.20310968 -1.27543468  0.24257896 -0.01042331\n",
      "  0.32691305  0.24257896 -1.19110059  0.7485835  -0.93809831 -1.27543468\n",
      "  1.08591987  1.00158577 -0.1790915   0.24257896  0.41124714 -0.34775968\n",
      " -2.11877558 -0.43209377 -0.09475741 -0.09475741 -0.51642786  1.92926077\n",
      "  0.15824487  2.01359486  0.49558123 -0.1790915   1.92926077  0.91725168\n",
      "  0.7485835  -0.1790915  -0.34775968 -2.20310968  0.32691305  1.17025396\n",
      "  0.41124714 -1.86577331 -0.01042331  2.01359486  0.49558123  0.24257896\n",
      " -0.85376422 -0.09475741  0.15824487  0.83291759  0.24257896  1.25458805\n",
      "  0.07391078 -1.44410286  1.92926077  0.32691305  0.57991532  1.08591987\n",
      "  0.41124714 -0.34775968 -0.01042331 -1.78143922  1.25458805 -1.27543468\n",
      "  0.57991532 -1.10676649  1.08591987 -0.51642786 -0.43209377  0.57991532\n",
      "  1.08591987 -0.60076195  0.32691305 -1.19110059  1.00158577 -0.34775968\n",
      " -0.34775968  0.41124714  0.07391078 -1.10676649  0.49558123 -1.44410286\n",
      " -0.93809831  0.49558123  0.57991532 -1.10676649  0.32691305  0.57991532\n",
      " -1.27543468 -0.26342559  0.24257896 -2.79344831 -0.34775968  0.32691305\n",
      " -1.61277104 -0.26342559 -0.34775968 -0.93809831 -0.68509604 -1.61277104\n",
      " -0.51642786  0.24257896 -2.03444149 -0.09475741 -2.11877558 -0.68509604\n",
      " -0.1790915  -0.68509604 -0.1790915  -0.60076195 -1.10676649  1.42325623\n",
      " -1.10676649 -0.93809831  0.7485835  -2.45611195 -0.68509604 -0.93809831\n",
      "  0.07391078 -1.0224324  -0.34775968  0.32691305  0.49558123 -0.76943013\n",
      " -0.09475741  0.07391078  1.25458805  0.49558123]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:8] = scaler.fit_transform(X_val.iloc[:, 0:8])\n",
      "/tmp/ipykernel_456912/2476877814.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.21033902 -1.09494631  0.13355753 -0.48069439  0.21033902 -0.4039129\n",
      " -0.86460184  1.13171689  0.363902    2.05309477  1.66918732  0.05677604\n",
      "  0.51746497 -0.17356843 -0.25034992 -1.01816482 -2.32345014 -0.63425737\n",
      "  0.51746497  0.59424646 -0.32713141  0.21033902  0.28712051 -0.32713141\n",
      "  1.0549354   0.28712051 -1.1717278   0.59424646  0.97815391  0.21033902\n",
      "  0.74780944 -0.17356843 -1.8627612   1.36206136  1.20849838 -0.17356843\n",
      "  1.59240583 -0.86460184 -0.71103886 -0.86460184 -0.09678694  0.28712051\n",
      " -0.32713141  0.28712051 -1.78597971 -1.01816482 -2.01632418  1.59240583\n",
      " -2.09310567  0.363902   -1.24850929  0.51746497 -0.55747588  0.67102795\n",
      " -2.09310567  0.74780944 -0.48069439 -0.25034992 -0.48069439 -0.32713141\n",
      "  0.97815391  1.28527987 -0.09678694 -0.32713141  0.05677604 -0.63425737\n",
      "  0.90137242  1.43884285  0.05677604 -0.4039129  -0.94138333  0.90137242\n",
      "  0.74780944  0.59424646 -0.32713141 -1.47885375  0.67102795 -0.78782035\n",
      " -1.09494631 -0.48069439 -0.86460184  1.13171689 -0.63425737  0.44068349\n",
      "  1.13171689 -1.47885375  0.363902   -0.78782035 -0.94138333  0.363902\n",
      " -2.01632418  0.21033902  1.28527987 -0.48069439  0.28712051 -0.32713141\n",
      " -0.32713141  0.97815391 -0.48069439 -1.47885375 -1.70919822 -0.48069439\n",
      " -0.63425737  0.82459093  0.51746497 -1.24850929  1.43884285  1.28527987\n",
      "  0.28712051  0.97815391  0.97815391 -0.94138333 -1.01816482 -1.70919822\n",
      " -0.63425737  0.82459093 -0.17356843  0.13355753 -1.8627612  -0.94138333\n",
      " -1.63241673  1.0549354   0.74780944 -2.24666865 -0.09678694  0.51746497\n",
      "  0.67102795  0.90137242 -1.40207227  0.363902   -1.09494631  0.82459093\n",
      "  0.44068349 -1.32529078 -1.32529078 -0.71103886 -0.17356843 -0.02000545\n",
      " -0.09678694 -1.24850929  0.59424646 -0.48069439  1.43884285  1.51562434\n",
      " -0.94138333  1.0549354   0.13355753 -0.09678694 -0.17356843  0.28712051\n",
      " -0.78782035 -0.94138333 -0.94138333 -1.32529078  0.82459093  0.97815391\n",
      " -0.63425737  0.363902   -0.17356843 -1.09494631  0.44068349 -0.63425737\n",
      " -0.02000545 -1.78597971  0.82459093  0.363902    0.74780944  0.05677604\n",
      " -1.01816482 -1.93954269  0.28712051  1.36206136  0.21033902 -1.93954269\n",
      " -1.1717278  -1.47885375 -0.63425737 -0.32713141  0.363902    0.05677604\n",
      "  0.67102795 -1.1717278   0.59424646 -0.71103886  0.59424646 -0.63425737\n",
      " -0.55747588  0.28712051  0.363902    1.36206136 -1.01816482  1.59240583\n",
      "  0.82459093  1.0549354  -0.94138333 -0.78782035 -0.32713141 -1.78597971\n",
      " -1.8627612   0.90137242 -1.1717278  -0.4039129   0.13355753  0.51746497\n",
      " -0.4039129   0.59424646  0.59424646 -1.01816482  1.97631328  0.363902\n",
      "  0.59424646 -2.01632418 -0.09678694 -0.02000545  0.363902    1.28527987\n",
      "  0.67102795 -0.55747588 -0.55747588  1.20849838  0.44068349 -1.01816482\n",
      " -0.17356843 -0.25034992  1.74596881 -0.4039129   1.0549354  -0.02000545\n",
      " -2.09310567  0.363902    2.12987626  0.59424646 -0.02000545  0.51746497\n",
      "  0.74780944  0.28712051 -2.47701312 -1.01816482  2.05309477  0.67102795\n",
      "  0.44068349 -0.55747588 -1.40207227 -0.71103886 -0.48069439  1.36206136\n",
      "  0.51746497  0.44068349  0.21033902 -0.17356843  0.05677604 -0.78782035\n",
      "  1.13171689 -0.48069439 -1.70919822  2.89769115 -0.17356843 -0.78782035\n",
      "  1.36206136 -0.02000545  0.59424646  0.05677604 -0.78782035 -0.71103886\n",
      "  0.82459093  0.59424646 -0.4039129  -0.94138333  0.82459093  0.74780944\n",
      "  1.97631328  0.51746497  0.90137242 -1.47885375 -0.48069439  0.28712051\n",
      " -0.09678694 -2.16988716  0.21033902  1.43884285  1.43884285  0.13355753\n",
      "  0.13355753  0.21033902  1.20849838 -2.32345014  0.363902    0.13355753\n",
      " -1.8627612  -0.4039129   0.21033902 -0.48069439  0.363902    1.28527987\n",
      "  0.74780944 -1.32529078 -1.47885375  0.05677604  0.82459093  0.82459093\n",
      "  0.59424646  0.05677604  0.363902   -0.55747588 -0.09678694 -0.4039129\n",
      " -0.09678694 -1.1717278  -0.32713141  1.66918732 -1.55563524 -1.01816482\n",
      " -0.94138333 -0.86460184  0.44068349 -1.1717278  -0.32713141 -1.09494631\n",
      " -0.09678694 -1.78597971 -0.48069439  0.05677604 -0.09678694  1.13171689\n",
      "  1.74596881 -0.48069439 -0.94138333  0.59424646 -1.40207227  1.0549354\n",
      " -0.48069439  0.05677604 -1.24850929 -1.32529078  0.67102795  1.13171689\n",
      " -0.71103886 -0.48069439 -1.1717278   1.13171689  1.28527987  1.20849838\n",
      "  0.363902   -0.09678694  1.36206136  1.51562434  1.0549354  -1.1717278\n",
      "  0.67102795  2.05309477  0.44068349 -0.48069439 -1.47885375  0.05677604\n",
      " -0.32713141  1.0549354   0.13355753  0.82459093  2.12987626  2.12987626\n",
      "  1.20849838  1.36206136  0.05677604 -1.1717278  -0.02000545 -1.47885375\n",
      " -0.25034992 -0.02000545 -0.94138333  0.97815391 -0.17356843 -0.02000545\n",
      " -0.55747588  1.0549354  -0.17356843 -1.24850929 -0.4039129   0.05677604\n",
      "  1.13171689 -1.1717278   1.0549354  -1.78597971 -1.55563524  0.74780944\n",
      "  0.82459093 -0.25034992  1.36206136 -1.01816482  2.05309477 -0.86460184\n",
      "  0.05677604  0.51746497 -0.17356843  1.66918732  0.363902    0.363902\n",
      "  0.90137242 -0.94138333  1.36206136  0.13355753  0.21033902 -2.47701312\n",
      "  1.28527987  1.43884285  1.59240583 -0.09678694  0.363902    1.43884285\n",
      "  1.51562434  0.97815391 -1.32529078  0.13355753 -0.63425737  0.59424646\n",
      " -0.94138333  1.43884285 -0.86460184  1.28527987 -1.40207227  1.43884285\n",
      "  0.05677604  0.90137242  1.66918732  0.82459093 -0.71103886 -0.09678694\n",
      " -1.40207227  0.28712051  1.43884285  0.21033902  1.28527987 -0.32713141\n",
      " -0.55747588  0.05677604 -0.32713141 -1.24850929  2.12987626  1.13171689\n",
      "  0.05677604  0.90137242 -0.09678694  1.89953179  0.59424646 -1.09494631\n",
      " -0.09678694  1.20849838 -0.63425737 -0.55747588 -0.71103886  0.97815391\n",
      " -0.09678694 -0.55747588 -1.09494631  0.13355753  0.05677604  0.363902\n",
      "  0.97815391 -0.48069439  0.05677604  0.67102795 -0.4039129   0.21033902\n",
      "  0.51746497  1.97631328 -0.71103886 -0.4039129   2.05309477 -1.47885375\n",
      "  0.74780944  0.51746497  1.20849838  0.44068349  1.8227503   1.0549354\n",
      "  0.05677604 -2.47701312  1.36206136  1.43884285  1.8227503   1.66918732\n",
      "  0.21033902 -1.47885375  0.44068349  0.51746497 -1.70919822  0.363902\n",
      "  0.97815391 -2.55379461  0.44068349 -0.25034992  2.5137837  -0.78782035\n",
      "  0.90137242 -0.94138333  1.43884285  0.21033902 -0.09678694 -1.63241673\n",
      "  0.82459093 -0.78782035 -0.55747588 -0.32713141  0.05677604 -2.47701312\n",
      "  0.363902   -0.4039129   0.05677604 -1.47885375  0.97815391  0.67102795\n",
      "  1.28527987 -0.32713141 -0.48069439  0.44068349  0.67102795  0.13355753\n",
      " -1.55563524 -0.17356843  0.59424646 -1.01816482 -0.48069439  0.363902\n",
      "  0.90137242 -0.25034992 -0.55747588  0.21033902 -0.48069439 -1.24850929\n",
      " -0.78782035 -0.09678694 -0.71103886  0.05677604 -0.48069439 -0.17356843\n",
      " -1.24850929 -0.78782035  0.05677604 -1.24850929 -0.09678694 -0.55747588\n",
      "  0.21033902 -0.55747588  0.90137242  0.13355753 -1.01816482]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:8] = scaler.fit_transform(X_val.iloc[:, 0:8])\n",
      "/tmp/ipykernel_456912/2476877814.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.4790469  -0.12592865  0.61348591  0.00851036  0.54626641 -0.52924569\n",
      " -1.94085531 -1.06700173  0.27738838  1.15124196 -0.05870915  1.01680294\n",
      "  0.00851036 -0.19314816  0.34460789  0.07572987 -0.7309042  -0.26036766\n",
      " -0.26036766 -0.39480667 -0.39480667  0.00851036  0.00851036 -0.46202618\n",
      " -0.19314816  0.00851036  0.41182739  0.34460789  2.42841256  1.28568097\n",
      "  1.42011998  0.68070542 -0.46202618 -1.94085531 -1.33587975  0.14294937\n",
      "  0.68070542 -0.86534321 -0.6636847   0.88236393  0.4790469  -0.99978223\n",
      " -1.06700173  0.81514443 -1.53753827 -1.67197728 -1.47031877 -2.00807481\n",
      " -2.07529432 -1.33587975 -0.99978223  0.34460789 -1.20144074  1.08402245\n",
      " -0.26036766  0.14294937 -0.12592865 -2.00807481  0.68070542  0.07572987\n",
      " -0.19314816 -0.86534321  0.14294937  1.75621751  2.29397355  0.00851036\n",
      "  0.81514443 -0.32758717 -0.46202618  0.00851036 -0.19314816  1.28568097\n",
      " -0.26036766 -0.12592865 -1.8736358   0.54626641  0.68070542  1.75621751\n",
      " -0.93256272  0.21016888 -0.26036766 -1.26866025 -1.06700173  0.00851036\n",
      " -0.46202618 -0.39480667 -0.05870915 -0.12592865  0.94958344 -0.52924569\n",
      " -0.6636847   0.81514443  0.81514443 -1.26866025 -0.6636847  -0.19314816\n",
      " -0.39480667 -0.93256272 -0.86534321  0.14294937 -0.26036766 -1.8736358\n",
      "  0.54626641  0.81514443  1.08402245 -0.7309042   0.4790469   0.14294937\n",
      "  1.55455899 -0.99978223  0.94958344 -0.32758717 -0.93256272 -0.6636847\n",
      " -0.6636847   0.81514443  0.74792492 -1.33587975 -1.06700173 -0.6636847\n",
      " -0.39480667 -0.39480667  0.61348591 -0.26036766 -0.32758717 -0.05870915\n",
      " -0.26036766  2.8317296  -2.07529432  0.21016888  0.81514443 -0.99978223\n",
      " -0.79812371 -1.8736358   2.29397355 -0.26036766  1.55455899 -2.00807481\n",
      "  0.14294937 -0.32758717 -1.73919679 -0.52924569 -2.00807481  0.94958344\n",
      " -1.06700173  0.41182739 -0.32758717  1.6217785   0.88236393  1.15124196\n",
      " -1.33587975 -1.26866025  0.00851036  0.61348591 -0.79812371 -0.26036766\n",
      " -1.53753827 -1.47031877 -1.33587975  0.81514443  0.88236393 -0.6636847\n",
      "  1.75621751  1.688998   -1.13422124 -0.46202618  0.14294937 -0.46202618\n",
      " -0.39480667  0.14294937  2.29397355 -0.26036766 -0.05870915 -1.26866025\n",
      " -0.46202618  1.28568097 -2.07529432 -1.47031877  2.63007108 -0.46202618\n",
      " -0.05870915 -0.46202618 -0.7309042  -0.26036766  0.74792492  2.09231504\n",
      "  1.01680294  0.88236393 -0.6636847  -1.40309926  0.54626641  0.68070542\n",
      " -0.26036766  0.14294937  0.14294937 -0.05870915 -2.00807481 -1.8736358\n",
      "  0.61348591  0.21016888 -0.12592865 -1.26866025 -0.39480667 -0.7309042\n",
      " -1.60475778  0.41182739 -0.19314816  1.75621751 -0.6636847   0.54626641\n",
      "  0.94958344  0.21016888 -1.20144074 -0.7309042   0.68070542 -0.86534321\n",
      "  0.94958344 -1.13422124 -0.19314816 -0.52924569  1.08402245 -0.19314816\n",
      " -1.33587975 -1.8736358   0.68070542  1.15124196 -2.07529432  1.08402245\n",
      " -1.13422124 -0.79812371  0.07572987  0.81514443  1.21846146 -0.32758717\n",
      "  0.41182739 -1.26866025  0.27738838  0.4790469  -0.12592865  1.75621751\n",
      " -0.26036766 -0.86534321 -1.33587975 -0.32758717  0.81514443 -0.26036766\n",
      " -0.86534321  1.48733948  1.01680294  2.49563207  0.61348591 -0.59646519\n",
      " -1.06700173  1.95787602  1.688998   -0.39480667 -0.99978223 -0.26036766\n",
      "  1.01680294  0.14294937 -0.86534321  0.41182739  0.14294937  1.75621751\n",
      "  2.8989491  -0.05870915  0.27738838 -0.12592865  1.82343701 -0.59646519\n",
      " -0.39480667  1.75621751  0.81514443 -0.93256272  1.55455899  0.61348591\n",
      " -0.79812371  0.94958344 -0.6636847  -0.59646519  1.55455899  0.14294937\n",
      "  2.29397355 -0.46202618 -0.19314816  0.4790469   1.01680294 -0.12592865\n",
      "  1.28568097  2.56285158  0.61348591  0.81514443  2.02509553  0.27738838\n",
      "  1.688998    1.01680294 -0.59646519  1.01680294 -0.86534321 -0.99978223\n",
      "  0.07572987 -0.86534321  0.94958344  0.4790469   0.34460789 -0.05870915\n",
      "  0.14294937 -2.00807481 -0.26036766 -0.7309042   0.14294937  0.68070542\n",
      "  0.88236393 -0.86534321 -0.6636847  -1.20144074 -1.06700173 -0.12592865\n",
      "  0.88236393 -0.6636847   1.21846146  0.74792492 -0.19314816 -0.05870915\n",
      "  1.688998    0.61348591  0.81514443 -0.6636847   0.74792492  1.15124196\n",
      " -0.12592865  1.08402245 -1.60475778  2.02509553  0.00851036  0.94958344\n",
      " -0.79812371 -1.47031877 -1.60475778 -0.7309042  -0.19314816 -1.20144074\n",
      " -0.12592865  0.07572987 -1.20144074 -0.6636847  -0.59646519 -1.33587975\n",
      " -0.12592865 -0.19314816  0.61348591  2.63007108 -0.19314816 -0.7309042\n",
      " -0.39480667 -0.26036766 -0.52924569 -1.60475778 -0.39480667 -0.26036766\n",
      "  0.41182739  0.61348591 -1.20144074 -0.32758717  1.01680294  1.28568097\n",
      "  1.82343701 -0.12592865 -0.12592865  1.35290047 -0.26036766  0.68070542\n",
      " -0.12592865  0.14294937 -0.39480667  2.15953454  1.35290047 -2.07529432\n",
      " -0.6636847   0.61348591  0.74792492 -1.26866025 -0.19314816  0.00851036\n",
      "  0.07572987 -1.26866025 -0.26036766 -0.79812371 -0.99978223 -1.33587975\n",
      " -1.26866025 -0.26036766 -0.6636847  -0.99978223  2.15953454 -0.19314816\n",
      " -0.46202618 -0.26036766 -1.26866025  0.74792492 -0.39480667 -0.19314816\n",
      " -0.26036766  0.4790469  -0.26036766  1.28568097  1.42011998 -0.7309042\n",
      "  1.35290047  0.61348591  0.88236393  1.21846146 -0.7309042   0.27738838\n",
      " -0.86534321  0.88236393 -0.6636847  -0.93256272  0.21016888 -1.8736358\n",
      "  0.68070542  0.14294937  0.68070542 -0.59646519 -1.73919679  0.68070542\n",
      " -1.60475778  0.00851036 -0.39480667  1.95787602 -0.26036766  0.14294937\n",
      " -0.6636847   0.4790469   1.28568097  0.21016888 -0.7309042  -0.79812371\n",
      " -1.20144074  0.81514443 -1.33587975  2.63007108 -0.79812371 -0.26036766\n",
      "  0.54626641 -0.39480667 -1.26866025 -1.20144074 -1.33587975  0.4790469\n",
      "  2.02509553 -0.59646519 -0.39480667 -0.19314816  1.08402245 -0.52924569\n",
      " -0.46202618 -1.20144074  0.41182739  0.88236393 -0.6636847   0.81514443\n",
      "  0.41182739  1.48733948  0.07572987 -1.60475778 -0.05870915  1.01680294\n",
      "  0.94958344 -1.33587975  0.81514443 -0.59646519  0.00851036  0.07572987\n",
      "  0.14294937  2.22675405 -1.47031877  0.34460789  2.09231504 -0.93256272\n",
      "  0.34460789 -1.20144074 -0.7309042   0.74792492  0.54626641  1.28568097\n",
      "  0.68070542 -2.07529432 -0.39480667 -0.79812371 -0.26036766 -0.26036766\n",
      " -0.12592865 -0.26036766  0.00851036  0.4790469   0.81514443  0.00851036\n",
      "  0.61348591 -0.19314816  0.68070542 -0.19314816  0.74792492  0.34460789\n",
      "  0.54626641 -0.7309042   0.21016888  0.00851036  0.14294937 -0.05870915\n",
      "  0.88236393  1.01680294 -0.26036766  0.4790469   0.34460789  2.02509553\n",
      " -0.05870915  1.688998    0.61348591 -0.79812371 -0.39480667 -0.39480667\n",
      " -0.39480667  0.61348591  0.4790469  -0.39480667 -1.13422124 -0.05870915\n",
      "  0.74792492  1.95787602  0.14294937 -0.12592865  0.07572987 -0.12592865\n",
      "  0.34460789 -1.26866025  0.68070542 -0.12592865  0.74792492 -1.47031877\n",
      "  1.35290047  1.28568097 -0.46202618  0.94958344 -0.86534321]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:8] = scaler.fit_transform(X_val.iloc[:, 0:8])\n",
      "/tmp/ipykernel_456912/2476877814.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.10510069  0.82226051  1.95362122 -1.49702895  1.55764497  0.82226051\n",
      " -0.81821252  0.87882855  1.4445089  -0.1393961   1.16166872  1.16166872\n",
      " -0.36566824  0.99196462  1.16166872 -0.81821252 -0.47880431  1.04853265\n",
      "  0.70912444  0.87882855  0.59598837 -0.02626002 -0.81821252 -1.72330109\n",
      " -0.08282806  1.16166872  1.33137283  0.08687605 -0.02626002  1.61421301\n",
      " -1.1010527  -1.44046091 -0.76164449  0.36971623  2.01018926  1.84048515\n",
      " -0.70507645 -0.98791663 -1.83643716 -0.3091002   1.95362122 -1.1010527\n",
      " -0.25253217  0.53942033 -0.70507645 -1.21418877  0.25658015 -1.21418877\n",
      " -2.23241341  0.36971623 -0.59194038  0.4828523  -0.42223627 -0.59194038\n",
      " -0.64850842 -0.93134859 -1.1010527   0.36971623  0.03030801 -0.42223627\n",
      "  2.06675729 -0.64850842  0.20001212 -0.3091002   0.70912444  0.93539658\n",
      "  0.93539658  1.50107694  0.70912444  2.46273354 -0.08282806 -1.44046091\n",
      " -1.49702895 -1.1010527  -0.59194038 -0.70507645  0.76569247 -0.25253217\n",
      "  0.82226051 -1.1010527  -0.25253217  0.99196462 -0.19596413 -0.02626002\n",
      " -0.47880431 -0.1393961  -0.76164449 -0.08282806 -1.21418877 -0.64850842\n",
      "  0.99196462 -0.08282806 -0.42223627  0.25658015  0.03030801 -0.93134859\n",
      " -0.70507645 -0.93134859 -0.70507645  0.20001212 -0.93134859 -0.59194038\n",
      " -0.36566824  0.42628426 -0.64850842 -0.70507645  0.93539658  0.99196462\n",
      "  2.63243765 -1.27075681  1.4445089   0.59598837 -0.70507645 -0.1393961\n",
      "  0.6525564  -0.59194038 -0.08282806  0.31314819  0.99196462 -2.00614127\n",
      "  0.36971623  0.70912444 -1.27075681 -0.98791663  0.25658015  0.03030801\n",
      " -0.47880431  0.08687605 -0.70507645  1.10510069 -0.1393961  -0.25253217\n",
      " -0.70507645 -0.53537234 -1.27075681  0.14344408  1.78391712 -0.47880431\n",
      " -0.36566824 -0.08282806  0.03030801 -1.38389288  0.14344408 -0.87478056\n",
      " -0.02626002  0.25658015 -0.70507645 -0.87478056  0.99196462 -2.00614127\n",
      " -1.32732484 -1.49702895 -0.36566824  0.76569247  1.21823676  0.4828523\n",
      " -0.53537234 -0.47880431 -0.42223627 -0.70507645 -0.1393961  -0.02626002\n",
      "  0.20001212  2.12332533 -0.36566824  0.99196462 -0.36566824  3.65066229\n",
      " -0.81821252 -1.32732484  0.59598837 -0.98791663  0.08687605  0.14344408\n",
      " -0.42223627 -0.19596413 -0.87478056 -1.32732484 -0.70507645  0.70912444\n",
      " -0.93134859  0.08687605 -0.36566824 -1.61016502 -0.36566824 -0.08282806\n",
      "  0.14344408 -0.93134859  0.76569247  0.25658015 -1.1010527  -0.81821252\n",
      " -0.47880431  0.31314819 -0.36566824 -0.1393961  -0.42223627 -0.64850842\n",
      " -1.04448466 -0.02626002 -1.27075681  1.21823676 -0.87478056 -1.55359699\n",
      "  2.29302944 -0.64850842 -0.70507645 -1.04448466  1.27480479  0.14344408\n",
      "  0.99196462 -0.64850842 -1.15762074 -1.04448466 -0.70507645 -1.04448466\n",
      "  0.4828523   0.42628426 -0.53537234 -0.76164449 -0.93134859 -0.98791663\n",
      " -0.93134859 -1.77986913  1.27480479 -1.04448466  0.03030801  2.29302944\n",
      " -0.64850842 -0.25253217  0.59598837  0.76569247 -0.70507645 -0.1393961\n",
      " -0.64850842 -0.87478056  1.50107694 -0.59194038  2.01018926 -0.81821252\n",
      "  0.25658015 -0.3091002  -1.55359699 -1.1010527   0.03030801  1.21823676\n",
      "  0.4828523  -0.93134859 -1.27075681 -0.81821252  1.78391712 -1.49702895\n",
      "  1.67078104  0.87882855  0.25658015  1.55764497 -0.87478056 -1.04448466\n",
      "  2.40616551 -1.27075681 -0.25253217 -0.98791663 -0.36566824 -0.47880431\n",
      "  0.76569247 -0.93134859 -0.47880431 -0.53537234 -0.53537234  0.6525564\n",
      " -0.08282806  0.42628426  0.59598837 -0.76164449 -0.36566824 -0.81821252\n",
      " -0.59194038  0.14344408  0.93539658 -0.64850842  0.99196462  0.99196462\n",
      " -0.42223627 -1.55359699 -0.36566824  0.36971623 -1.49702895 -0.59194038\n",
      " -1.21418877  0.31314819  0.25658015 -0.64850842  0.59598837 -0.36566824\n",
      " -1.32732484 -0.3091002  -0.81821252 -0.1393961  -2.00614127 -0.1393961\n",
      "  0.6525564  -0.19596413  0.76569247 -0.02626002 -0.02626002  0.70912444\n",
      " -0.3091002  -1.27075681 -0.47880431  0.25658015 -1.04448466  2.46273354\n",
      " -0.87478056 -0.47880431  0.03030801 -1.55359699  0.03030801 -0.87478056\n",
      "  1.04853265 -1.44046091 -0.02626002  0.93539658 -0.42223627 -1.27075681\n",
      "  2.12332533 -0.3091002  -0.42223627 -0.47880431 -1.04448466 -2.28898145\n",
      "  0.76569247 -1.27075681 -0.81821252 -0.3091002   0.4828523   1.38794087\n",
      "  1.84048515 -0.1393961  -1.27075681 -0.3091002   0.14344408 -0.53537234\n",
      " -1.15762074  0.87882855  0.59598837  0.14344408 -0.93134859 -1.1010527\n",
      "  0.93539658  0.4828523  -1.04448466  0.6525564   0.14344408  0.99196462\n",
      " -0.47880431  0.14344408  0.76569247 -0.47880431 -0.1393961  -1.44046091\n",
      "  0.76569247  1.33137283 -0.87478056  1.16166872  2.12332533 -0.1393961\n",
      " -0.59194038  0.31314819 -0.42223627  3.76379836  1.38794087 -0.36566824\n",
      " -0.08282806  1.50107694 -0.02626002  1.72734908  0.53942033  2.01018926\n",
      " -0.53537234 -0.3091002   0.31314819 -0.36566824 -0.47880431  1.78391712\n",
      "  0.99196462 -0.76164449 -0.53537234  0.53942033 -0.08282806  3.19811801\n",
      " -0.1393961   0.4828523  -0.93134859 -0.02626002  0.36971623 -0.70507645\n",
      " -0.25253217  0.20001212 -0.53537234 -0.98791663 -0.59194038  1.84048515\n",
      "  0.99196462  1.33137283 -0.53537234 -1.1010527   0.20001212  2.29302944\n",
      "  1.16166872 -0.36566824 -0.53537234  0.20001212 -1.15762074  0.08687605\n",
      "  0.82226051  0.87882855 -0.08282806  0.53942033 -1.1010527   1.10510069\n",
      " -0.53537234 -0.59194038 -0.64850842 -0.93134859 -0.08282806  0.03030801\n",
      " -1.04448466 -1.1010527   0.4828523  -0.02626002  0.20001212  0.93539658\n",
      "  0.6525564  -0.53537234  0.20001212  0.53942033 -0.1393961  -0.25253217\n",
      " -0.64850842 -0.1393961   1.50107694  0.14344408  1.50107694 -0.70507645\n",
      "  2.40616551  0.36971623  1.21823676 -0.1393961  -0.87478056 -1.27075681\n",
      " -0.93134859  0.4828523   0.53942033 -0.3091002   0.36971623  0.36971623\n",
      "  0.6525564   0.25658015  0.76569247  3.08498193 -1.32732484 -0.64850842\n",
      "  0.25658015 -0.98791663 -0.3091002   0.70912444  0.70912444  0.87882855\n",
      " -0.53537234  0.42628426 -0.02626002 -0.47880431 -0.53537234 -1.1010527\n",
      " -0.42223627  1.04853265  0.87882855  0.36971623 -0.81821252  0.14344408\n",
      "  1.50107694 -0.19596413 -0.47880431 -0.87478056 -0.3091002  -0.93134859\n",
      "  0.25658015  1.78391712 -1.55359699  1.78391712 -0.53537234  0.4828523\n",
      "  0.36971623 -1.61016502 -1.04448466 -0.81821252  1.78391712 -0.1393961\n",
      "  0.20001212  1.10510069  0.42628426  0.99196462  0.70912444 -1.94957323\n",
      "  0.25658015  1.16166872  0.25658015  2.80214176 -1.77986913  2.57586961\n",
      " -0.3091002  -0.1393961  -0.76164449  0.76569247 -0.36566824  0.14344408\n",
      "  1.67078104  1.78391712  1.33137283 -1.77986913 -0.76164449 -0.76164449\n",
      "  0.6525564   0.42628426  1.04853265  2.29302944 -0.36566824  1.04853265\n",
      " -0.25253217  1.27480479 -0.02626002  0.4828523  -0.76164449  0.08687605\n",
      "  2.97184586 -0.1393961  -0.25253217  0.31314819  0.03030801 -0.59194038\n",
      "  0.08687605  1.50107694 -1.27075681  0.59598837 -0.93134859]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:8] = scaler.fit_transform(X_val.iloc[:, 0:8])\n",
      "/tmp/ipykernel_456912/2476877814.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.64313062  1.64313062  1.81381702 -1.34388135  1.64313062 -0.40510616\n",
      "  0.10695304 -0.06373336  1.81381702 -0.49044936  0.53366903  1.72847382\n",
      " -0.31976296  0.96038503  2.15518982 -0.06373336 -0.31976296  0.36298263\n",
      "  0.61901223  0.02160984  0.87504183 -0.40510616 -0.57579256 -0.57579256\n",
      "  0.02160984  1.72847382  0.87504183 -0.40510616 -0.74647896  2.15518982\n",
      " -0.31976296 -0.31976296 -0.91716535  0.36298263 -0.83182216  1.98450342\n",
      " -1.51456775 -1.25853815 -1.77059735 -0.83182216  0.27763944 -1.17319495\n",
      " -0.31976296  0.19229624  0.44832583 -0.91716535 -0.49044936 -0.66113576\n",
      " -1.68525415  0.70435543 -0.49044936  0.61901223  0.02160984 -0.40510616\n",
      " -0.91716535  0.19229624  0.36298263  0.53366903  0.53366903 -0.14907656\n",
      "  0.70435543 -1.08785175  0.53366903  0.53366903  0.36298263  0.53366903\n",
      "  0.96038503  0.61901223  1.13107143  2.32587622  0.70435543 -1.25853815\n",
      " -0.91716535 -0.91716535  0.02160984  0.87504183 -0.06373336  0.53366903\n",
      "  0.70435543 -0.66113576  0.53366903  0.36298263 -0.83182216  0.02160984\n",
      " -0.74647896  0.19229624 -0.40510616  0.78969863 -0.66113576  0.02160984\n",
      "  3.52068101  0.96038503  0.44832583  0.19229624  0.78969863 -0.57579256\n",
      " -1.17319495 -0.49044936  0.10695304 -0.40510616 -0.83182216 -0.49044936\n",
      "  0.10695304  0.44832583 -0.23441976 -0.31976296  0.78969863  2.32587622\n",
      "  0.61901223 -0.74647896 -0.23441976  0.96038503 -1.17319495 -0.74647896\n",
      " -1.17319495 -1.51456775 -0.40510616  0.44832583  0.96038503 -0.66113576\n",
      "  0.10695304 -1.59991095 -0.31976296 -1.59991095 -0.23441976 -0.31976296\n",
      " -1.08785175  0.44832583 -0.40510616  0.10695304  0.78969863 -0.83182216\n",
      " -0.14907656 -0.06373336 -1.59991095 -0.40510616  1.81381702 -0.74647896\n",
      "  0.19229624  0.70435543  0.02160984 -1.00250855 -0.31976296 -0.14907656\n",
      "  0.70435543 -0.40510616 -0.74647896 -0.14907656  1.38710103 -2.02662694\n",
      " -0.14907656 -0.06373336 -0.49044936  1.81381702  0.19229624 -1.17319495\n",
      "  0.27763944  0.96038503 -0.31976296 -1.25853815 -1.42922455  0.19229624\n",
      "  0.96038503  0.96038503  0.53366903  0.19229624  0.70435543  2.58190582\n",
      " -0.40510616 -1.17319495  0.27763944 -1.00250855  0.53366903  0.53366903\n",
      " -1.08785175  0.78969863 -0.06373336 -1.25853815 -1.00250855  0.96038503\n",
      " -1.25853815  0.19229624 -0.31976296 -1.68525415 -1.25853815 -0.57579256\n",
      " -0.14907656  0.27763944  0.61901223 -0.66113576 -2.53868614  0.10695304\n",
      " -0.49044936  0.27763944 -0.49044936  0.10695304 -0.49044936 -0.23441976\n",
      " -0.57579256 -1.17319495 -0.23441976  1.64313062 -0.66113576 -1.42922455\n",
      "  3.8620538  -0.91716535 -1.25853815 -0.31976296 -0.66113576  0.36298263\n",
      "  0.87504183 -0.49044936 -1.85594055 -0.31976296 -0.23441976 -0.40510616\n",
      "  0.87504183  0.61901223 -0.31976296 -0.66113576 -0.14907656  0.02160984\n",
      " -2.19731334 -1.34388135 -0.66113576 -0.83182216 -0.49044936  2.49656262\n",
      " -1.59991095  0.36298263  0.10695304  0.78969863 -0.40510616 -0.14907656\n",
      " -0.31976296 -0.49044936  0.44832583 -0.31976296 -0.74647896 -0.57579256\n",
      "  0.02160984 -0.14907656  0.70435543 -0.31976296  1.21641463 -0.14907656\n",
      "  0.19229624  1.04572823 -0.40510616 -0.83182216  1.30175783 -0.49044936\n",
      "  1.55778742  1.72847382  0.78969863 -0.66113576 -0.06373336 -0.66113576\n",
      "  1.21641463 -0.57579256  0.19229624  0.10695304  0.70435543 -2.19731334\n",
      " -0.31976296 -0.49044936 -0.06373336  0.19229624 -0.66113576 -0.31976296\n",
      " -0.74647896 -0.57579256 -0.14907656 -1.94128375  0.70435543 -0.06373336\n",
      " -1.94128375  0.96038503  1.81381702 -0.40510616 -0.40510616 -0.31976296\n",
      " -0.06373336 -1.08785175 -0.49044936  1.89916022 -1.08785175 -0.66113576\n",
      " -0.14907656  0.96038503  0.27763944 -1.42922455  0.70435543 -0.57579256\n",
      " -0.66113576  1.04572823  0.02160984 -0.40510616 -1.85594055 -0.23441976\n",
      "  0.53366903  0.36298263  0.87504183 -1.25853815 -0.23441976  1.72847382\n",
      " -0.06373336 -0.74647896  0.36298263 -0.57579256 -2.28265654  4.0327402\n",
      " -1.08785175 -0.14907656 -0.31976296 -0.66113576 -0.23441976 -0.23441976\n",
      "  0.53366903 -2.28265654  0.02160984  2.49656262  0.27763944 -1.85594055\n",
      "  0.44832583 -0.23441976  0.19229624  0.44832583 -0.57579256 -1.00250855\n",
      " -0.06373336 -0.40510616  0.02160984  0.02160984  0.36298263 -0.40510616\n",
      "  1.55778742  0.27763944 -0.66113576 -1.25853815 -0.31976296 -0.66113576\n",
      " -0.66113576  1.55778742  1.13107143 -0.57579256 -0.49044936 -1.42922455\n",
      " -1.17319495 -1.42922455 -0.31976296  1.38710103 -0.06373336  0.10695304\n",
      "  0.02160984  0.78969863  1.13107143 -1.00250855 -0.91716535 -1.94128375\n",
      "  0.44832583 -0.49044936 -0.23441976  2.41121942  1.38710103  0.27763944\n",
      " -0.06373336  0.36298263  0.61901223  1.64313062  1.30175783 -1.08785175\n",
      "  0.27763944  0.87504183  0.02160984  2.06984662 -0.31976296  1.55778742\n",
      " -1.34388135  0.19229624 -0.06373336  0.78969863  0.27763944 -1.17319495\n",
      "  0.19229624 -0.31976296 -0.66113576  0.27763944 -1.42922455  3.09396501\n",
      "  0.78969863 -0.91716535  0.44832583 -1.08785175  0.10695304  0.19229624\n",
      " -1.00250855 -0.14907656 -0.31976296  1.04572823 -0.06373336  1.38710103\n",
      "  0.10695304 -1.08785175 -1.77059735  1.30175783  0.02160984  0.19229624\n",
      "  1.89916022  0.87504183 -1.59991095  0.02160984 -0.74647896  0.10695304\n",
      " -0.14907656 -0.40510616  1.21641463  0.10695304 -0.66113576  0.19229624\n",
      "  0.19229624 -0.40510616 -0.06373336  0.10695304  0.78969863 -0.40510616\n",
      "  0.36298263 -0.23441976 -0.57579256  1.30175783 -1.25853815  1.30175783\n",
      "  0.78969863 -0.83182216 -0.66113576  1.81381702 -1.08785175 -0.91716535\n",
      " -2.53868614  0.53366903  1.04572823 -0.31976296 -0.40510616 -0.40510616\n",
      "  1.81381702 -0.06373336  1.47244423  0.53366903 -0.49044936 -1.77059735\n",
      "  0.19229624 -0.23441976  1.04572823 -0.14907656 -0.23441976  1.04572823\n",
      " -0.31976296  0.87504183 -0.66113576  1.81381702 -0.66113576  0.27763944\n",
      "  0.27763944 -1.34388135  0.36298263  0.61901223 -1.25853815  1.47244423\n",
      " -0.40510616  0.44832583 -0.83182216 -1.08785175 -1.59991095 -0.91716535\n",
      "  0.10695304  1.13107143  0.61901223  0.19229624 -1.17319495 -1.17319495\n",
      "  0.27763944  0.10695304 -0.83182216 -0.74647896  0.44832583 -0.31976296\n",
      " -0.23441976  3.52068101 -1.68525415  2.24053302 -0.74647896  0.36298263\n",
      "  0.53366903 -1.51456775 -1.25853815  0.36298263  1.81381702 -0.31976296\n",
      " -1.08785175  0.70435543  1.30175783  0.78969863  0.27763944 -1.59991095\n",
      "  0.36298263  1.30175783  0.61901223 -0.40510616 -0.91716535  0.02160984\n",
      " -0.66113576  0.44832583 -0.14907656  0.19229624 -0.31976296 -0.40510616\n",
      "  1.64313062  1.55778742 -0.40510616 -1.25853815  0.19229624 -1.08785175\n",
      "  0.87504183  1.04572823  0.78969863  1.55778742  0.19229624  0.70435543\n",
      " -0.23441976  1.55778742  0.70435543 -0.66113576 -1.08785175  0.53366903\n",
      "  3.00862181 -1.08785175  0.61901223  1.38710103  0.02160984 -0.31976296\n",
      "  0.27763944  1.98450342 -1.00250855  0.27763944 -0.57579256]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:8] = scaler.fit_transform(X_val.iloc[:, 0:8])\n",
      "/tmp/ipykernel_456912/2476877814.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.10356219 -0.20423996  0.19847109 ... -2.01643968  0.29914886\n",
      " -0.00288443]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:8] = scaler.fit_transform(X_val.iloc[:, 0:8])\n",
      "/tmp/ipykernel_456912/2476877814.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.52349431 -0.52349431 -2.18041077 ... -0.52349431 -0.52349431\n",
      " -0.52349431]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:8] = scaler.fit_transform(X_val.iloc[:, 0:8])\n",
      "/tmp/ipykernel_456912/2476877814.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.75012643 -2.1173535  -0.39686554 ... -0.39686554  0.17663044\n",
      " -0.39686554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_val.iloc[:, 0:8] = scaler.fit_transform(X_val.iloc[:, 0:8])\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n",
      "/tmp/ipykernel_456912/2698080489.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'LR+': (tp / (tp + fn)) / (1 - (tn / (tn + fp))) if (tn + fp) != 0 and (tp + fn) != 0 else float('inf'),\n",
      "/tmp/ipykernel_456912/2698080489.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'DOR': ((tp / (tp + fn)) / (1 - (tn / (tn + fp)))) / ((1 - (tp / (tp + fn))) / (tn / (tn + fp)))\n"
     ]
    }
   ],
   "source": [
    "def evaluate_single_validation_set(df, model, scaler):\n",
    "    X_val = df[set3]\n",
    "    y_val = df['IHA']\n",
    "    X_val.iloc[:, 0:8] = scaler.fit_transform(X_val.iloc[:, 0:8])  \n",
    "    \n",
    "    y_prob = model.predict_proba(X_val)[:, 1]\n",
    "    return bootstrap_metrics(y_val, y_prob)\n",
    "\n",
    "# Evaluate on validation sets\n",
    "results_df2 = evaluate_on_validation_sets(model, validation_sets, scaler)\n",
    "\n",
    "results_df1.to_csv('~/data/BAH_PRS/version10/ml_dat/conpass_training_boot_model3.csv', index=True)\n",
    "for key, value in results_df2.items():\n",
    "    value.to_csv(f'~/data/BAH_PRS/version10/ml_dat/{key}_boot_model3.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e61eb5-9d87-4c7d-8bea-6202e3215886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpfn",
   "language": "python",
   "name": "tabpfn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
